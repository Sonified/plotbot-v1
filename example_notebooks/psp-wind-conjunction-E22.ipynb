{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import winsound\n",
    "# import pyaudio as winsound\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import datetime as dt\n",
    "import urllib\n",
    "import cdflib as cdf\n",
    "\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "import scipy.signal\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import LogNorm,Normalize\n",
    "\n",
    "from collections import defaultdict\n",
    "import pytplot\n",
    "from pytplot import time_datetime\n",
    "from pyspedas import time_string,time_double,tinterpol\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "### Add functions from functions.ipynb, located in folder (str)\n",
    "import sys as sys\n",
    "if '/Users/sfordin/Documents/Science-Projects' not in sys.path:\n",
    "    sys.path.append('/Users/sfordin/Documents/Science-Projects')\n",
    "if '/Users/sfordin/Plotbot' not in sys.path:\n",
    "    sys.path.append('/Users/sfordin/Plotbot')\n",
    "\n",
    "from plotbot import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "# import ipynb\n",
    "# from ipynb.fs.defs.functions import (read_mfi,mfi_varsnip,read_3dp,thrdp_varsnip,read_swe,swe_varsnip,\n",
    "#                                      read_solo_mag,read_solo_swa,solo_mag_varsnip,solo_swa_varsnip,\n",
    "#                                      highpass,lowpass,bandpass,mva,chunk,resample,\n",
    "#                                      padded_power,freqs_from_fft_peaks,mva_subintervals,wavelet_spec,boxcar_ave,Wavelet2Go)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d1e8d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "plt.rcParams['axes.xmargin'] = 0\n",
    "plt.rcParams['axes.ymargin'] = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ddbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92182417",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "### COMPUTE WAVELET TRANSFORM ON LONG INTERVALS\n",
    "###############################################\n",
    "\n",
    "## B : array-like (Nx3); \n",
    "##     use np.vstack for correct shape\n",
    "\n",
    "## V,T,np : 0 or array-like\n",
    "##         cadence of V,T,np should match that of B when given to wavelet2Long\n",
    "\n",
    "## delta_t : instrument cadence\n",
    "\n",
    "\n",
    "def wavelet2Long(t_range,B,V=0,T=0,n_p=0,delta_t = 1/16,f_n = 128,f_min = 1e-3,f_max=8,percent_COI=0.2):\n",
    "\n",
    "    ## 0. Initialize B,V,T,n\n",
    "    \n",
    "    ## B    \n",
    "    df = pd.DataFrame(data=np.vstack((B[0][t_range[0]:t_range[1]],B[1][t_range[0]:t_range[1]],B[2][t_range[0]:t_range[1]])).T,columns=['Bx','By','Bz'])\n",
    "    if df['Bx'].isna().sum()/len(df.Bx)<=0.1 and df['By'].isna().sum()/len(df.By)<=0.1 and df['Bz'].isna().sum()/len(df.Bz)<=0.1 :\n",
    "        df=df.interpolate()\n",
    "        df=df.dropna()\n",
    "\n",
    "        mu_0 = 4*np.pi*1e-7#N/A^2=kg.m/(s^2.A^2)\n",
    "        m_proton=1.673*1e-27#kg\n",
    "        \n",
    "        if n_p is 0:\n",
    "            rho = 7*m_proton*1e6*5/6 # kg m^{-3} see Good et al. 2022 MNRAS for more details\n",
    "        else:\n",
    "            rho = m_proton * n_p\n",
    "        # playing around with random values\n",
    "        if V is 0:\n",
    "            vx_n = np.repeat(400*1e3,df.Bx.shape[0]) # m/s\n",
    "            vy_n = np.repeat(30*1e3,df.Bx.shape[0]) # m/s\n",
    "            vz_n = np.repeat(-40*1e3,df.Bx.shape[0]) # m/s\n",
    "\n",
    "        else:\n",
    "            vx_n = V[0][t_range[0]:t_range[1]]\n",
    "            vy_n = V[1][t_range[0]:t_range[1]]\n",
    "            vz_n = V[2][t_range[0]:t_range[1]]\n",
    "\n",
    "            z_plusx = vx_n+bx_n\n",
    "            z_plusy = vy_n+by_n\n",
    "            z_plusz = vz_n+bz_n\n",
    "\n",
    "            z_minusx=vx_n-bx_n\n",
    "            z_minusy=vy_n-by_n\n",
    "            z_minusz=vz_n-bz_n\n",
    "            \n",
    "        bx_n = (1e-9*df.Bx)/np.sqrt(mu_0*rho) # m/s\n",
    "        by_n = (1e-9*df.By)/np.sqrt(mu_0*rho) # m/s\n",
    "        bz_n = (1e-9*df.Bz)/np.sqrt(mu_0*rho) # m/s\n",
    "        \n",
    "        radi=180/(4*np.arctan(1))\n",
    "        ph=radi*np.arctan2(df.By,df.Bx)\n",
    "        gg=np.where((ph < 0)); \n",
    "        for i in gg:\n",
    "            ph[i]=radi*np.arctan2(df.By[i],df.Bx[i])+360.\n",
    "        \n",
    "        #select the inertial range (1e-4-1e-2 hz), dt=1min=60sec\n",
    "        # print('uo')\n",
    "        my_wavelet2go = Wavelet2Go(f_n=f_n, f_min=f_min, f_max=f_max, dt=delta_t) # Telloni et al 2020\n",
    "        yticks,ytickfreqs = my_wavelet2go.get_y_ticks(reduction_to=5)\n",
    "        xticks,xtickfreqs = my_wavelet2go.get_x_ticks(reduction_to=int(60*(60/delta_t)/2),data=df.Bx)\n",
    "        cwtbfx, freqs = my_wavelet2go.perform_transform(df.Bx-np.mean(df.Bx))\n",
    "        cwtbfy, freqs = my_wavelet2go.perform_transform(df.By-np.mean(df.By))\n",
    "        cwtbfz, freqs = my_wavelet2go.perform_transform(df.Bz-np.mean(df.Bz))   \n",
    "\n",
    "        eb_fluc = abs(cwtbfx)**2+abs(cwtbfy)**2+abs(cwtbfz)**2\n",
    "\n",
    "        cwtbx, freqs = my_wavelet2go.perform_transform(df.Bx)\n",
    "        cwtby, freqs = my_wavelet2go.perform_transform(df.By)\n",
    "        cwtbz, freqs = my_wavelet2go.perform_transform(df.Bz)\n",
    "\n",
    "        \n",
    "        a=2*(np.conj(cwtby)*cwtbz).imag\n",
    "        b=(abs(cwtby)**2+abs(cwtbz)**2)\n",
    "        a=my_wavelet2go.mask_invalid_data(a, fill_value=0)\n",
    "        b=my_wavelet2go.mask_invalid_data(b, fill_value=0)\n",
    "        sigm = a/b                \n",
    "\n",
    "        ## truncate time series based on cone of influence to avoid edge effects\n",
    "        trunc_len = percent_COI * (t_range[1]-t_range[0])\n",
    "        trunc_range = (int(t_range[0] + trunc_len),int(t_range[1]-trunc_len))\n",
    "        # print('Complete:' + str(trunc_range) + ' from total length ' + str(B[0].size))\n",
    "    return trunc_range,freqs,eb_fluc,sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c938309",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zoom into phi_B and identify rotations in phi_B\n",
    "def phinder(phi_B,strong_thresh = 135):\n",
    "    \n",
    "    \n",
    "    o_flag = 1 # current orientation of phi_B; +/-1 corresponds to changing left/right bound\n",
    "    double_fail = 0 # if double_fail > 1, return indices of magnetic field rotation\n",
    "    \n",
    "    l = 0\n",
    "    r = phi_B.size\n",
    "\n",
    "    while r - l > 1:\n",
    "        \n",
    "        ### define subinterval of contiguous interval with moving left bound\n",
    "        sub_inds = [l,r]\n",
    "        phi_B_int = phi_B[sub_inds[0]:sub_inds[1]]\n",
    "\n",
    "        if o_flag > 0:\n",
    "            phi_0_int = phi_B_int[0]\n",
    "        elif o_flag < 0:\n",
    "            phi_0_int = phi_B_int[-1]\n",
    "\n",
    "\n",
    "        gamma = np.absolute(phi_B_int - phi_0_int)       # total angular difference\n",
    "        chord = 2 * np.sin(np.deg2rad(gamma/2))          # length of chord on unit circle defined by gamma\n",
    "\n",
    "        ang_diff = 2 * np.rad2deg(np.arcsin(chord/2))    # angle subtended by chord on unit circle defined by gamma \n",
    "        ang_diff_max = np.max(ang_diff)\n",
    "            \n",
    "        if ang_diff_max > strong_thresh:\n",
    "\n",
    "            if o_flag > 0:\n",
    "                r = l + np.where(ang_diff > strong_thresh)[0][0]\n",
    "\n",
    "            elif o_flag < 0:\n",
    "                l = l + np.where(ang_diff > strong_thresh)[0][-1]    \n",
    "                \n",
    "            rot_bounds = [l,r]\n",
    "            double_fail = 0\n",
    "\n",
    "            o_flag = -1 * o_flag\n",
    "        \n",
    "        if o_flag > 0:\n",
    "            l += 1\n",
    "\n",
    "        if o_flag < 0:\n",
    "            r += 1\n",
    "\n",
    "        if double_fail > 1:\n",
    "            break\n",
    "                      \n",
    "    try:\n",
    "        return rot_bounds\n",
    "    except:\n",
    "        return [np.nan,np.nan]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9181f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Autochordelation\n",
    "####################\n",
    "### Find indices associated with large rotations in phi_B with recursion\n",
    "### Compute angles subtended by chords between points on unit circle given by phi_B_ds \n",
    "        # Loop 1: - Choose an interval and compute initial \n",
    "            # Loop 2: - Iterate through each angle and compute chord length relative to initial angle\n",
    "            #         - If subtended angles satisfy criteria:\n",
    "                # Loop 3: - Find shortest subinterval that satisfies the criteria \n",
    "                #         - Record final index of shortest subinterval and use as index of next initial angle\n",
    "                #         - Record midpoint of shortest subinterval as single \"time of rotation\"\n",
    "### Return indices of rotation bounds\n",
    "### Return indices of rotation midpoints\n",
    "\n",
    "def autochord(phi_B,strong_thresh = 135,weak_thresh = 90):\n",
    "    \n",
    "\n",
    "    j = 0\n",
    "    rot_bounds = []\n",
    "    num_empty = 0\n",
    "    while j < phi_B.size:\n",
    "        \n",
    "        ### define subinterval iterating over the left bound\n",
    "        phi_B_int = phi_B[j:] # interval of phi_B for autochordelation\n",
    "        phi_0 = phi_B_int[0]         # initial phi_B to check against: first phi_B_median\n",
    "\n",
    "        gamma = np.absolute(phi_B_int - phi_0)        # total angular difference\n",
    "        chord = 2 * np.sin(np.deg2rad(gamma/2))       # length of chord on unit circle defined by gamma\n",
    "        \n",
    "        ang_diff = 2 * np.rad2deg(np.arcsin(chord/2)) # angle subtended by chord on unit circle defined by gamma\n",
    "        ang_diff_max = np.max(ang_diff)               # index of maximum angular difference in contiguous interval\n",
    "\n",
    "        if ang_diff_max > strong_thresh:\n",
    "            \n",
    "            # zoom into interval by moving left bound until failure, then right bound until failure, etc\n",
    "            rot_inds = phinder(phi_B_int,strong_thresh=strong_thresh)\n",
    "\n",
    "            rot_bounds.append([j + rot_inds[0] , j + rot_inds[1]])\n",
    "\n",
    "            j += rot_inds[1] # update new position to last added right bound\n",
    "        else:\n",
    "            j += 1\n",
    "            num_empty += 1\n",
    "\n",
    "    rot_midpoints = [int(0.5*(rot_bounds[i][0]+rot_bounds[i][1])) for i in range(len(rot_bounds))]\n",
    "\n",
    "    return rot_bounds,rot_midpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5592703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt2cal(dt):\n",
    "    \"\"\"\n",
    "    Convert array of datetime64 to a calendar array of year, month, day, hour,\n",
    "    minute, seconds, microsecond with these quantites indexed on the last axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dt : datetime64 array (...)\n",
    "        numpy.ndarray of datetimes of arbitrary shape\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cal : uint32 array (..., 7)\n",
    "        calendar array with last axis representing year, month, day, hour,\n",
    "        minute, second, microsecond\n",
    "    \"\"\"\n",
    "\n",
    "    # allocate output \n",
    "    out = np.empty(dt.shape + (7,), dtype=\"u4\")\n",
    "    # decompose calendar floors\n",
    "    Y, M, D, h, m, s = [dt.astype(f\"M8[{x}]\") for x in \"YMDhms\"]\n",
    "    out[..., 0] = Y + 1970 # Gregorian Year\n",
    "    out[..., 1] = (M - Y) + 1 # month\n",
    "    out[..., 2] = (D - M) + 1 # dat\n",
    "    out[..., 3] = (dt - D).astype(\"m8[h]\") # hour\n",
    "    out[..., 4] = (dt - h).astype(\"m8[m]\") # minute\n",
    "    out[..., 5] = (dt - m).astype(\"m8[s]\") # second\n",
    "    out[..., 6] = (dt - s).astype(\"m8[us]\") # microsecond\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get tasteful tick datetime display for a time array\n",
    "    # Determines which unit should be used for the tick labels\n",
    "    # ideally, this unit should be the largest one that changes between the tick labels and is easy to interpret\n",
    "\n",
    "def tasteful_ticks(t,num_ticks = 6):\n",
    "\n",
    "\n",
    "## 1. Compute total timedelta between first/last epochs\n",
    "    t_dt64 = cdf.cdfepoch.to_datetime(t)\n",
    "\n",
    "    # list of calendar units [Y,M,D,h,m,s,us]\n",
    "    t_cal = dt2cal(t_dt64)\n",
    "\n",
    "\n",
    "    tick_cal_list = np.array_split(t_cal,num_ticks)\n",
    "    split_mid = int(tick_cal_list[0].shape[0]/2)\n",
    "    tick_cal_list = [tick_cal_list[i][split_mid] for i in range(len(tick_cal_list))]\n",
    "    tick_strf_list = [dt.datetime(year=tick_cal_list[i][0],month=tick_cal_list[i][1],day=tick_cal_list[i][2],\n",
    "                                  hour=tick_cal_list[i][3],minute=tick_cal_list[i][4],second=tick_cal_list[i][5],\n",
    "                                  microsecond=tick_cal_list[i][6]).strftime('%y/%m/%d %H:%M:%S.%f') for i in range(len(tick_cal_list))]\n",
    "\n",
    "    # diff time in cal units between tick labels\n",
    "    d_tick = [np.argmax(tick_cal_list[i+1] - tick_cal_list[i] > 0) for i in range(len(tick_cal_list) - 1)]\n",
    "\n",
    "    # identify total number of changing labels and for each label \n",
    "\n",
    "    # units of change that are largest for more than 1 interval (i.e. the important changing units)\n",
    "    d_tick_units_to_change = np.asarray(np.unique(d_tick,return_counts=True))\n",
    "    d_tick_units_to_change = d_tick_units_to_change[0][np.where(d_tick_units_to_change[1] > 1)]\n",
    "\n",
    "\n",
    "    # locations of ticks based on time array\n",
    "    tick_locs = np.array_split(t,num_ticks)\n",
    "    tick_locs = [tick_locs[i][split_mid] for i in range(len(tick_locs))]\n",
    "\n",
    "\n",
    "    # for each t_cal to be referenced in ticks, identify the units to be used based on smallest unit and total number of units\n",
    "    # hard code cases for multiple units of change\n",
    "    if d_tick_units_to_change.size > 1:\n",
    "        uoc = d_tick_units_to_change[-2]\n",
    "    else:\n",
    "        uoc = d_tick_units_to_change[0]\n",
    "\n",
    "    # hard code strings\n",
    "    if uoc == 0:\n",
    "        tick_labels = [tick_strf_list[i][0:2] + '-' + tick_strf_list[i][3:5] for i in range(len(tick_cal_list))]\n",
    "    elif uoc == 1:\n",
    "        tick_labels = [tick_strf_list[i][3:5] + '-' + tick_strf_list[i][6:8] for i in range(len(tick_cal_list))]\n",
    "    elif uoc == 2:\n",
    "        tick_labels = [tick_strf_list[i][3:5] + '-' + tick_strf_list[i][6:8] for i in range(len(tick_cal_list))]\n",
    "    elif uoc == 3:\n",
    "        tick_labels = [tick_strf_list[i][9:11] + ':' + tick_strf_list[i][12:14] for i in range(len(tick_cal_list))]\n",
    "    elif uoc == 4:\n",
    "        tick_labels = [tick_strf_list[i][12:14] + ':' + tick_strf_list[i][13:15] for i in range(len(tick_cal_list))]\n",
    "    elif uoc == 5:\n",
    "        tick_labels = [tick_strf_list[i][13:15] + '.' + tick_strf_list[i][16:] for i in range(len(tick_cal_list))]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return tick_locs,tick_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2242b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "########################################################################\n",
    "\n",
    "            ### HELIOSPHERIC CURRENT SHEET CROSSING AUTOMATION ###\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "\n",
    "def hcs_loc(tpad,tB,epad,phi_B,med_filter_len = 25, buffer_range = 1,parapar_rats = [1/3,3],beam_bg_rats = [2/3,3/2],return_bounds=False):\n",
    "\n",
    "########################################################################\n",
    "### QUESTIONS: \n",
    "########################################################################\n",
    "\n",
    "### Basic HCS phenomenology:\n",
    "\n",
    "# - Does strahl inversion \"always\" happen at 1 au for HCS crossings? \n",
    "        # Might we instead expect strahl dropout + reestablishment in the same direction on each side of hcs?\n",
    "\n",
    "# - What constitutes a large change in the azimuth of B?\n",
    "        # Adam Szabo: \"135 degrees is typical\"\n",
    "        # Liou 2021: \"120 degrees is the accepted degree of rotation\"\n",
    "        # Also Liou 2021: \"Average is 137 degrees, but 30% of HCS crossings have < 120 degree field rotation\" gaaaaaah how are these identified as HCS crossings\n",
    "\n",
    "\n",
    "### Methodology:\n",
    "\n",
    "# - Is it acceptable to directly compare counts in the first and last angular bins to establish strahl direction?\n",
    "        # If so, what constitutes a \"large\" ratio of counts for unidirectionality? 1.5? 3? 10?\n",
    "        # What are the widths of the pitch angle bins at each time step for EESA-Low? Can't find anywhere...\n",
    "\n",
    "# - Can the prominence of the strahl be measured using the combined parallel/anti-parallel bin counts \n",
    "#   compared to sum of all counts in other bins?\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "### Davin's paper\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "### FIRST ATTEMPT: STEPS TO AUTOMATE DETECTION\n",
    "########################################################################\n",
    "\n",
    "### 1. Using strahl metrics, quantify interval types using flags (strong parallel, strong anti-parallel, weak and/or bi-directional strahl)\n",
    "\n",
    "### 2. Using data flags, mark regions of changing strahl (where strahl changes from one type to another)\n",
    "\n",
    "### 3. Within flagged regions, use phi_B metrics to quantify data types (large, moderate, small phi_B rotation)\n",
    "\n",
    "### 4. Identify HCS crossing times using a final flag\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# tpad: time array associated with epad\n",
    "# tB: time array associated with phi_B\n",
    "# epad: N x A x C array, where N is len(tpad), A is no. of solid angle bins, C is # energy channels\n",
    "# phi_B: array of phi_B measurements\n",
    "\n",
    "\n",
    "\n",
    "    ### 1. Strahl metrics and flags\n",
    "\n",
    "    # Choose bins associated with parallel/anti-parallel strahl\n",
    "\n",
    "    par_bins = [0,1]\n",
    "    antipar_bins = [-2,-1]\n",
    "    bg_bins = [i for i in range(len(par_bins), 1 + 8 - len(antipar_bins))]\n",
    "\n",
    "    par_counts = 1/len(par_bins)*np.sum(epad[:,par_bins],axis=1)\n",
    "    par_counts = scipy.signal.medfilt(par_counts,kernel_size=med_filter_len)\n",
    "\n",
    "    antipar_counts = 1/len(antipar_bins)*np.sum(epad[:,antipar_bins],axis=1)\n",
    "    antipar_counts = scipy.signal.medfilt(antipar_counts,kernel_size=med_filter_len)\n",
    "\n",
    "    bg_counts = 1/len(bg_bins)*np.sum(epad[:,bg_bins],axis=1)\n",
    "    bg_counts = scipy.signal.medfilt(bg_counts,kernel_size=med_filter_len)\n",
    "\n",
    "\n",
    "\n",
    "    ### Flag 1: Ratio of parallel to anti-parallel counts at each time step\n",
    "    ### Assumption: 3 types of data intervals (parallel, bi-directional, anti-parallel)\n",
    "    # Flag of  1 = strahl is parallel        \n",
    "    #      of  0 =           bidirectional   \n",
    "    #      of -1=            anti-parallel   \n",
    "\n",
    "    unidir_ratio = par_counts/antipar_counts\n",
    "    unidir_flag = np.digitize(unidir_ratio, bins = parapar_rats) - 1\n",
    "\n",
    "\n",
    "    ### Flag 2: Ratio of total strahl intervals to halo (assumed to be remainder of energy channel)\n",
    "    ### Assumption: 3 types of data intervals (dense beam, moderate beam, diffuse beam)\n",
    "    # Flag of  1 = total beam greater than halo ( > 3/2 )\n",
    "    #      of  0 =            similar to        ( 2/3 - 3/2 )\n",
    "    #      of -1=             smaller than      ( < 2/3 )\n",
    "\n",
    "    # make flags for par/antipar separately (unblur) \n",
    "\n",
    "    par_atrop_ratio = par_counts/bg_counts\n",
    "    antipar_atrop_ratio = antipar_counts/bg_counts\n",
    "\n",
    "    par_atrop_flag = np.digitize(par_atrop_ratio, bins = beam_bg_rats) - 1\n",
    "    antipar_atrop_flag = np.digitize(antipar_atrop_ratio, bins = beam_bg_rats) - 1\n",
    "\n",
    "\n",
    "\n",
    "    ########################################################################\n",
    "\n",
    "    ### 2. Using data flags, mark regions of changing strahl properties\n",
    "\n",
    "\n",
    "    ### We define time ranges based on the intervals between distinct strahl directions\n",
    "    ### Using flags 1 and 2, we can identify regions in which the strahl is changing between \n",
    "    ### parallel and anti-parallel\n",
    "\n",
    "    ### Flag 3: Type of strahl\n",
    "    ### Assumption: 3 types of data intervals (strong parallel beam, strong anti-parallel beam, bi-directional or unresolved strahl)\n",
    "    # Flag of  1 = strahl is strong and parallel\n",
    "    #      of  0 =           weak or bi-directional \n",
    "    #      of -1 =           strong and anti-parallel\n",
    "\n",
    "    strahl_type_flag = np.zeros(tpad.size)\n",
    "\n",
    "    # Identify measurements with strong or moderate prominence, unidirectional strahl\n",
    "    par_strahl_inds = np.intersect1d(np.where(unidir_flag == 1),np.where(par_atrop_flag > 0))\n",
    "    antipar_strahl_inds = np.intersect1d(np.where(unidir_flag == -1),np.where(antipar_atrop_flag > 0))\n",
    "\n",
    "    strahl_type_flag[par_strahl_inds] = 1\n",
    "    strahl_type_flag[antipar_strahl_inds] = -1\n",
    "\n",
    "    ### Flag 4: Get hcs-type strahl\n",
    "    ### Flag of 1 = hcs-type (weak/bi-directional)\n",
    "    ###      of 0 = non-hcs-type\n",
    "\n",
    "    hcs_strahl_flag = np.zeros(tpad.size)\n",
    "    hcs_strahl_flag[strahl_type_flag == 0] = 1\n",
    "\n",
    "    strahl_flag_regions  = np.split(hcs_strahl_flag,np.where(np.diff(hcs_strahl_flag))[0] + 1)\n",
    "    strahl_flag_regions_inds  = np.split(np.arange(0,tpad.size),np.where(np.diff(hcs_strahl_flag))[0] + 1)\n",
    "\n",
    "\n",
    "\n",
    "    ########################################################################\n",
    "\n",
    "    ### 3. Within contiguous regions, use phi_B metrics to quantify data types\n",
    "\n",
    "    ### To define the intervals in which we check phi_B, first identify every time in which align_flag switches from +/-1 to another value. For each of these times, \n",
    "    ### find the first time at which both align_flag switches sign AND strahl_halo_flag = 1. (The first time is when we lose the strahl; the second time is when the strahl comes \n",
    "    ### back with a different orientation.)\n",
    "\n",
    "    ###  Once these intervals have been identified, phi_B can be diagnosed. How can we do this?\n",
    "    ### Backing up. How do we actually track changes in phi_B?\n",
    "    ### A \"true\" change in phi_B is equivalent to a change in the length of the chord connecting the positions on the unit circle subtending \n",
    "    ### the two measurements of phi_B.\n",
    "\n",
    "\n",
    "    ### Q: Which chords should be used?\n",
    "    ### A: If we are searching within the strahl reversal time window, ideally we would start with the phi_B associated with each orientation of strahl\n",
    "    ### and compute chord length relative to each phi_B within the time window\n",
    "\n",
    "    ### Chord length = 2.00 for gamma = 180\n",
    "    ### Chord length = 1.85 for gamma = 135\n",
    "    ### Chord length = 1.41 for gamma = 90\n",
    "    ### Chord length = 1.00 for gamma = 60\n",
    "\n",
    "\n",
    "\n",
    "    ### Assumption: The initial phi_B by which we define angular differences is given by the initial and final strahl regions\n",
    "    ### Flag 4: phi_B rotation.                    OLD ### Flag 4: phi_B rotation compared to initial phi_B using chord_length\n",
    "    # Flag of 1  =  > 135                           OLD # Flag of 1 =  > 1.85\n",
    "    #      of 0  =  < 135                          OLD #      of 0 =  1.41-1.85\n",
    "    \n",
    "\n",
    "    strong_thresh = 135      # cutoff for weak azimuthal rotation\n",
    "    phi_B_flag = np.zeros(tpad.size)\n",
    "    phi_B_rots = np.zeros(tpad.size)\n",
    "\n",
    "    phi_B_ds = resample(phi_B,new_times=tpad,times=tB)[1] # resample phi_B at same cadence as PADs\n",
    "    phi_B_median = scipy.signal.medfilt(phi_B_ds,kernel_size = med_filter_len)\n",
    "\n",
    "    rot_bounds,rot_times = autochord(phi_B_median,strong_thresh=strong_thresh)\n",
    "\n",
    "    for i in range(len(rot_times)):\n",
    "        phi_B_flag[rot_bounds[i][0]:rot_bounds[i][1]] = 1\n",
    "        phi_B_rots[rot_times[i]] = 1\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "    ### 4. Identify HCS crossing times using a final flag \n",
    "\n",
    "\n",
    "    ### Implementation 1 returns the approximate rotation times (sector boundaries?) within the hcs\n",
    "    ### Implementation 2 returns the interval of strahl likely associated with the hcs + sector boundary based on whether there was a magnetic field rotation anywhere within it\n",
    "    \n",
    "\n",
    "\n",
    "    # Implementation 1: Simply multiply the strahl flag and phi_B flag. Nonzero values give times that are both rotating and inside hcs.\n",
    "    # hcs_sb == sector boundary flag\n",
    "    hcs_flag = phi_B_rots * hcs_strahl_flag\n",
    "    hcs_sb = np.where(hcs_flag > 0)\n",
    "\n",
    "    # Implementation 2: Using each region of changing strahl, check whether the magnetic field is rotating anywhere within; then label that section as \"inside hcs\"\n",
    "    hcs_flag = np.zeros(tpad.size)\n",
    "    hcs_bound_inds = []\n",
    "    for i in range(len(strahl_flag_regions)):\n",
    "        strahl_type = strahl_flag_regions[i][0]\n",
    "        if strahl_type == 1:\n",
    "            if len(strahl_flag_regions[i]) > 1:\n",
    "                i_s = strahl_flag_regions_inds[i][0] - buffer_range\n",
    "                i_e = strahl_flag_regions_inds[i][-1]  + buffer_range             # get first + last indices of changing-strahl regions and with a buffer given by buffer_range\n",
    "\n",
    "                check_phi_B = phi_B_flag[i_s:i_e]       # if there is at least one point of rotation interval within an interval of changing strahl, identify as being \"within the hcs\"\n",
    "                hcs_inds = np.where(check_phi_B > 0)[0]        # the check: is there a rotation within the region of changing strahl?\n",
    "            \n",
    "                if hcs_inds.size > 0:\n",
    "                    hcs_flag[i_s:i_e] = 1               # update final hcs based on rotation info flag\n",
    "                    hcs_bound_inds.append(i)\n",
    "\n",
    "\n",
    "    # return pairs of indices marking hcs region boundaries, paired [first,last]  \n",
    "    if return_bounds:\n",
    "        hcs_bounds = np.split(np.arange(0,tpad.size),np.where(np.diff(hcs_flag))[0] + 1)\n",
    "        hcs_bounds = [[hcs_bounds[i][0],hcs_bounds[i][-1]] for i in range(len(hcs_bounds)) if hcs_flag[hcs_bounds[i][0]] == 1]\n",
    "        return hcs_sb,hcs_bounds\n",
    "    else:\n",
    "        return hcs_sb,hcs_flag\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b737fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Secondary HCS detector\n",
    "# For each identified \"hcs\" region, check whether it demonstrates a true reversal in strahl direction\n",
    "\n",
    "# region_inds: pairs (i,j) of start + end indices of hcs to check\n",
    "# win_prop: win_len[k] = win_prop * len(region_inds[k])\n",
    "\n",
    "def strahl_walls(epad , pangles , region_inds , med_filter_len = 49 , win_prop = 2 , pad_thresh = 60):\n",
    "    \n",
    "    strahl_flip = [] # for each region_inds, check whether centroid changes\n",
    "\n",
    "    # get centroids of median-filtered epad\n",
    "    epad_med = scipy.signal.medfilt2d(epad[:,:],kernel_size=(med_filter_len,1))\n",
    "    centroids_epad = np.ma.average(pangles,weights=epad_med,axis=1)\n",
    "    \n",
    "    for k in range(len(region_inds)):\n",
    "        win_len = int((region_inds[k][1] - region_inds[k][0])/2) * win_prop\n",
    "        reg_mid = int((region_inds[k][1] + region_inds[k][0])/2)\n",
    "        win_s = np.max([reg_mid - win_len , 0])\n",
    "        win_e = np.min([reg_mid + win_len , centroids_epad.shape[0] - 1])\n",
    "        \n",
    "        cent_reg = centroids_epad[win_s:win_e]\n",
    "        max_diff = np.max(cent_reg) - np.min(cent_reg)\n",
    "        if max_diff > pad_thresh:\n",
    "            strahl_flip.append(k)        \n",
    "    \n",
    "    return strahl_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_manager.show_status = True\n",
    "\n",
    "### Test hcs finder on PSP E22\n",
    "\n",
    "# 1. Import tpad, tB, epad, phi_B\n",
    "trange = ['2024-12-23/00:00:00.000','2024-12-29/00:00:00.000']\n",
    "plotbot(trange,mag_rtn_4sa.bmag,1,epad.strahl,2)\n",
    "\n",
    "tpad = np.array(epad.time)\n",
    "tB = np.array(mag_rtn_4sa.time)\n",
    "epad_test = 10**np.array(epad.strahl.data)\n",
    "pangles = np.array(epad.pitch_angle_y_values)  # No .data needed - it's already a raw array\n",
    "Br = np.array(mag_rtn_4sa.br.data)\n",
    "Bn = np.array(mag_rtn_4sa.bn.data)\n",
    "\n",
    "phi_B = np.degrees(np.arctan2(Br,Bn)) + 180\n",
    "fig,ax=plt.subplots(1,1,figsize=(9.7,4))\n",
    "ax.scatter(tB,phi_B,s=3)\n",
    "ax.set_ylabel('degree \\n')\n",
    "\n",
    "# 2. Input tpad, tB, epad_test, phi_B into hcs_loc\n",
    "hcs_sb,hcs_bounds = hcs_loc(tpad,tB,epad_test,phi_B,parapar_rats = [1/3,3],beam_bg_rats = [2/3,3/2],return_bounds=True,med_filter_len=49)\n",
    "hcs_walls = strahl_walls(epad_test,pangles,region_inds=hcs_bounds)\n",
    "for k in hcs_sb[0]:\n",
    "    ax.axvline(tpad[k],ls='--',c='k')\n",
    "for i in hcs_walls:\n",
    "    ax.axvspan(tpad[hcs_bounds[i][0]],tpad[hcs_bounds[i][-1]],color='g',alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139abb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize Wind data\n",
    "### Choose data\n",
    "\n",
    "date = [2024,12,27,0,0,0]\n",
    "\n",
    "days = 5\n",
    "hours = 0\n",
    "minutes = 0\n",
    "\n",
    "date_e = [date[0] ,date[1], date[2] + days, date[3] + hours, date[4] + minutes, date[5]]\n",
    "\n",
    "key_list = []\n",
    "keylist_list = []\n",
    "\n",
    "# lists of rich text strings for plot labels \n",
    "label_list = []\n",
    "labellist_list = []\n",
    "\n",
    "kB = 1.38e-23\n",
    "mp = 1.67e-27\n",
    "\n",
    "\n",
    "try:\n",
    "    tB,Bmag,Bx,By,Bz = mfi_varsnip(date,hours = hours,days = days,dateloc='start')\n",
    "    phi_B = np.degrees(np.arctan2(Bx,By)) + 180\n",
    "    theta_B = np.degrees(np.arctan2(Bz,Bx)) + 180\n",
    "    \n",
    "    key_list_mfi = ['tB','Bmag','Bx','By','Bz','phi_B']\n",
    "    key_list.extend(key_list_mfi)\n",
    "    keylist_list.append(key_list_mfi)\n",
    "\n",
    "    label_list_mfi = ['$t$','$B$','$B_x$','$B_y$$','$B_z$','$\\phi_B$']\n",
    "    label_list.extend(label_list_mfi)\n",
    "    labellist_list.append(label_list_mfi)\n",
    "    \n",
    "except:\n",
    "    print('Error: MFI')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    t3pm,Vx,Vy,Vz,ni,na,p_temp,a_temp,flagpm = thrdp_varsnip(date,hours = hours,days = days,dateloc='start',isPAD=False)\n",
    "    Vmag = np.sqrt(Vx**2+Vy**2+Vz**2)\n",
    "    \n",
    "    key_list_3dppm = ['t3pm','Vmag','Vx','Vy','Vz','ni','na','p_temp','a_temp','flagpm']\n",
    "    key_list.extend(key_list_3dppm)\n",
    "    keylist_list.append(key_list_3dppm)\n",
    "    \n",
    "    label_list_3dppm = ['$t$','$V$','$V_x$','$V_y$','$V_z$','$n_p$','$n_a$','$T_p$','$T_a$','quality flag']\n",
    "    label_list.extend(label_list_3dppm)\n",
    "    labellist_list.append(label_list_3dppm)\n",
    "\n",
    "except:\n",
    "    print('Error: 3dp key params')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    t3pad,electronflux,pangle = thrdp_varsnip(date,hours = hours,days = days,dateloc='start',isPAD=True)\n",
    "    electronflux = np.nan_to_num(electronflux,0)\n",
    "    # ensure pangle uses \n",
    "    pangle_nan_fill = np.linspace(0,180,8)\n",
    "    for i in range(pangle.shape[0]):\n",
    "        if np.isnan(pangle[i]).any():\n",
    "            for j in range(8):\n",
    "                if np.isnan(pangle[i,j]):\n",
    "                    pangle[i,j] = pangle_nan_fill[j]\n",
    "\n",
    "    key_list_3dppad = ['t3pad','electronflux','pangle']\n",
    "    key_list.extend(key_list_3dppad)\n",
    "    keylist_list.append(key_list_3dppad)\n",
    "\n",
    "    label_list_3dppad = ['$t$','flux','pitch angle $(^\\\\degree)$']\n",
    "    label_list.extend(label_list_3dppad)\n",
    "    labellist_list.append(label_list_3dppad)\n",
    "\n",
    "except:\n",
    "    print('Error: 3dp PADs')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    tswepa,Wp,Wa,Vp,Va,tswee,Te,Wparp,Wperpp,Wpara,Wperpa,flagswe = swe_varsnip(date,hours = hours,days = days,dateloc='start',isPAD=False)\n",
    "    \n",
    "    Tperpp = 10**6 * Wperpp**2 * mp/ (2 * kB) / 11604\n",
    "    Tparp = 10**6 * Wparp**2 * mp/ (2 * kB) / 11604\n",
    "    Tparp[Tparp > 1000] = 0\n",
    "    Tperpp[Tperpp > 1000] = 0\n",
    "    \n",
    "    key_list_swepa = ['tswepa','Tperpp','Tparp','Wa','Vp','Va']\n",
    "    key_list_swee = ['tswee','Te','flagswe']\n",
    "    key_list.extend(key_list_swepa)\n",
    "    keylist_list.append(key_list_swepa)\n",
    "    key_list.extend(key_list_swee)\n",
    "    keylist_list.append(key_list_swee)\n",
    "\n",
    "    label_list_swepa = ['$t$','$T_{p,\\\\perp}$','$T_{p,\\\\parallel}$','$W_a$','$V_p$','$V_a$']\n",
    "    label_list_swee = ['$t$','$T_e$','quality flag']\n",
    "    label_list.extend(label_list_swepa)\n",
    "    labellist_list.append(label_list_swepa)\n",
    "    label_list.extend(label_list_swee)\n",
    "    labellist_list.append(label_list_swee)\n",
    "\n",
    "except:\n",
    "    print('Error: SWE temps')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    tswepad,e00,e01,e02,e03,e04,e05,e06,e07,e08,e09,e10,e11,e12 = swe_varsnip(date,hours = hours,days = days,dateloc='start',isPAD=True)\n",
    "    key_list_swepad = ['tswepad','e00','e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11','e12']\n",
    "    key_list.extend(key_list_swepad)\n",
    "    keylist_list.append(key_list_swepad)\n",
    "    \n",
    "    label_list_swepad = ['$t$','e00','e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11','e12']\n",
    "    label_list.extend(label_list_swepad)\n",
    "    labellist_list.append(label_list_swepad)\n",
    "except:\n",
    "    print('Error: SWE PADs')\n",
    "    pass\n",
    "\n",
    "epoch_choice = dict()\n",
    "for keylist in keylist_list:\n",
    "    for key in keylist[1:]:\n",
    "        epoch_choice[key] = keylist[0]\n",
    "\n",
    "\n",
    "# Get variable name from local variables based on dict key \n",
    "var_dict = dict()\n",
    "for i in (key_list):\n",
    "    var_dict[i] = locals()[i]\n",
    "\n",
    "label_dict = dict()\n",
    "for i in range(len(key_list)):\n",
    "    label_dict[key_list[i]] = label_list[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc527c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize SolO data\n",
    "date = [2024,12,24,0,0,0]\n",
    "\n",
    "days = 7\n",
    "hours = 0\n",
    "minutes = 0\n",
    "\n",
    "remake_label_lists = True\n",
    "\n",
    "if remake_label_lists:\n",
    "\n",
    "    ## dict of epoch references \n",
    "    epoch_choice = dict()\n",
    "\n",
    "    ## list of variable names to reference as strings\n",
    "    key_list = []\n",
    "    keylist_list = []\n",
    "\n",
    "    ## lists of rich text strings for plot labels \n",
    "    label_list = []\n",
    "    labellist_list = []\n",
    "\n",
    "\n",
    "date_e = [date[0] ,date[1], date[2] + days, date[3] + hours, date[4] + minutes, date[5]]\n",
    "\n",
    "key_list_solo = []\n",
    "keylist_list_solo = []\n",
    "\n",
    "# lists of rich text strings for plot labels \n",
    "label_list_solo = []\n",
    "labellist_list_solo = []\n",
    "\n",
    "kB = 1.38e-23\n",
    "mp = 1.67e-27\n",
    "\n",
    "try:\n",
    "    tB_solo,Bx_solo,By_solo,Bz_solo,flag_mag = solo_mag_varsnip(date,hours = hours,days = days,dateloc='start')\n",
    "    phi_B_solo = np.degrees(np.arctan2(Bx_solo,By_solo)) + 180\n",
    "    theta_B_solo = np.degrees(np.arctan2(Bz_solo,Bx_solo)) + 180\n",
    "    \n",
    "    key_list_mag = ['tB_solo','Bx_solo','By_solo','Bz_solo','phi_B_solo']\n",
    "    key_list.extend(key_list_mag)\n",
    "    keylist_list.append(key_list_mag)\n",
    "\n",
    "    label_list_mag = ['$t$','$B_x$','$B_y$','$B_z$','$\\phi_B$']\n",
    "    label_list.extend(label_list_mag)\n",
    "    labellist_list.append(label_list_mag)\n",
    "    \n",
    "except:\n",
    "    print('Error: SolO MAG')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    tp_solo,Vx_solo,Vy_solo,Vz_solo,Np_solo,Tx_solo,Ty_solo,Tz_solo,flag_swa = solo_swa_varsnip(date,hours = hours,days = days,dateloc='start')\n",
    "    key_list_swa = ['tp_solo','Vx_solo','Vy_solo','Vz_solo','Np_solo','Tx_solo','Ty_solo','Tz_solo','flag_swa']\n",
    "    key_list.extend(key_list_swa)\n",
    "    keylist_list.append(key_list_swa)\n",
    "\n",
    "    label_list_swa = ['$t$','$V_x$','$V_y$','$V_z$','$n_p$','$T_x$','$T_y$','$T_z$','flag']\n",
    "    label_list.extend(label_list_swa)\n",
    "    labellist_list.append(label_list_swa)\n",
    "    \n",
    "except:\n",
    "    print('Error: SolO SWA')\n",
    "    pass\n",
    "\n",
    "# lists of rich text strings for plot labels \n",
    "\n",
    "for keylist in keylist_list:\n",
    "    for key in keylist[1:]:\n",
    "        epoch_choice[key] = keylist[0]\n",
    "\n",
    "## Select time range\n",
    "for keylist in keylist_list:\n",
    "    for key in keylist[1:]:\n",
    "        epoch_choice[key] = keylist[0]\n",
    "\n",
    "# Select variable name \n",
    "var_dict = dict()\n",
    "for i in (key_list):\n",
    "    var_dict[i] = locals()[i]\n",
    "\n",
    "label_dict = dict()\n",
    "for i in range(len(key_list)):\n",
    "    label_dict[key_list[i]] = label_list[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ec6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot SolO data\n",
    "\n",
    "## list of (mixed-type) variable names given as single strings or as lists of strings\n",
    "\n",
    "plot_list = [['Bx_solo','By_solo','Bz_solo'],\n",
    "             'phi_B_solo',\n",
    "             ['Vx_solo','Vy_solo','Vz_solo'],\n",
    "             'Np_solo',\n",
    "             ['Tx_solo','Ty_solo','Tz_solo']]\n",
    "color_list = ['blue','orange','green']\n",
    "n = len(plot_list)\n",
    "ticklocs,ticklabels = tasteful_ticks(tp_solo)\n",
    "\n",
    "fig,ax=plt.subplots(n,1,figsize=(8,3 * n),layout='compressed')\n",
    "\n",
    "for i in range(0,n):\n",
    "\n",
    "    var_name = plot_list[i]\n",
    "    ## check type of var_name: \n",
    "    ##  -if it is a single variable name, plot that variable\n",
    "    ##  -if it is a list of variable name strings, obtain info for each variable and plot within same panel\n",
    "\n",
    "    ##  -str case\n",
    "    if type(var_name) is str:\n",
    "        t_name = epoch_choice[var_name]\n",
    "        var_ass = var_dict[var_name]\n",
    "        t_ass = var_dict[t_name]\n",
    "        plot_label = label_dict[var_name]\n",
    "        lt = np.shape(t_ass)[0]\n",
    "        ax[i].plot(t_ass,var_ass,label='{}'.format(plot_label))\n",
    "        ax[i].set_ylabel(r'{}'.format(plot_label))\n",
    "        if var_name == 'phi_B_solo':\n",
    "            ax[i].set_ylim([0,360])\n",
    "            ax[i].set_yticks([0,90,180,270,360])\n",
    "\n",
    "    ##  -list case\n",
    "    elif type(var_name) is list:\n",
    "        plot_ylabel = []\n",
    "        for k in range(len(var_name)):\n",
    "            \n",
    "            t_name = epoch_choice[var_name[k]]\n",
    "            \n",
    "            var_ass = var_dict[var_name[k]]\n",
    "            t_ass = var_dict[t_name]\n",
    "            \n",
    "            plot_label = label_dict[var_name[k]]\n",
    "            plot_ylabel.append(plot_label)\n",
    "\n",
    "            lt = np.shape(t_ass)[0]\n",
    "            ax[i].plot(t_ass,var_ass,color=color_list[k],label='{}'.format(plot_label))\n",
    "            if var_name[k] == 'phi_B_solo':\n",
    "                ax[i].set_ylim([0,360])\n",
    "                ax[i].set_yticks([0,90,180,270,360])\n",
    "    \n",
    "        ax[i].set_ylabel(r'{}'.format(plot_ylabel))\n",
    "        ax[i].legend(frameon=False,bbox_to_anchor=(1,1))\n",
    "\n",
    "    ax[i].set_xticks(ticklocs)\n",
    "    ax[i].set_xticklabels(ticklabels)\n",
    "    ax[i].locator_params(axis='x', nbins=6)\n",
    "    ax[i].yaxis.set_minor_locator(AutoMinorLocator(n = 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot solar wind parameters in time range\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "\n",
    "med_filter_len = 49\n",
    "\n",
    "phi_B_ds = resample(phi_B,new_times=t3pad,times=tB)[1] # resample phi_B at same cadence as PADs\n",
    "phi_B_median = scipy.signal.medfilt(phi_B_ds,kernel_size = med_filter_len)\n",
    "\n",
    "theta_B_ds = resample(theta_B,new_times=t3pad,times=tB)[1] # resample phi_B at same cadence as PADs\n",
    "theta_B_median = scipy.signal.medfilt(theta_B_ds,kernel_size = med_filter_len)\n",
    "\n",
    "hcs_sb,hcs_regions = hcs_loc(t3pad,tB,electronflux,phi_B,med_filter_len=med_filter_len,buffer_range=0,return_bounds=True)\n",
    "hcs_walls = strahl_walls(electronflux,pangle,region_inds=hcs_regions)\n",
    "\n",
    "rot_bounds,rot_mids = autochord(phi_B_median)\n",
    "\n",
    "# for j in range(len(rot_times)):\n",
    "#     plt.scatter(rot_bounds[j][0],phi_B_median[rot_bounds[j][0]],c='green',s=100)\n",
    "#     plt.scatter(rot_bounds[j][1],phi_B_median[rot_bounds[j][1]],c='green',s=100)\n",
    "fig,ax=plt.subplots(6,1,figsize=(10,18),layout='compressed')\n",
    "t3pad_mesh = np.expand_dims(t3pad,axis=0)\n",
    "t3pad_mesh = np.repeat(t3pad_mesh,8,axis=0).T\n",
    "cmap_min = np.max([np.ma.min(electronflux[:,:,4][electronflux[:,:,4] > 0]),1e3])\n",
    "cmap_max = np.min([np.ma.max(electronflux[:,:,4][electronflux[:,:,4] > 0]),4e5])\n",
    "\n",
    "# pcmesh = ax[0].pcolormesh(t3pad_mesh,pangle,(electronflux[:,:,4]),cmap='turbo',norm=colors.LogNorm(vmin=cmap_min,vmax=cmap_max),shading='gouraud')\n",
    "epad = electronflux[:,:,4]\n",
    "epad_med = scipy.signal.medfilt2d(epad,kernel_size=(med_filter_len,1))\n",
    "    \n",
    "epad_norm = np.zeros(epad.shape)\n",
    "epad_med_norm = np.zeros(epad.shape)\n",
    "for k in range(epad.shape[0]):\n",
    "    epad_ma = np.ma.array(epad[k,:],mask=epad[k,:] == 0)\n",
    "    col_sum = np.ma.sum(epad[k,:])\n",
    "    epad_norm[k,:] = epad_ma/col_sum if col_sum > 0 else 0\n",
    "\n",
    "    epad_ma = np.ma.array(epad_med[k,:],mask=epad_med[k,:] == 0)\n",
    "    col_sum = np.ma.sum(epad_med[k,:])\n",
    "    epad_med_norm[k,:] = epad_ma/col_sum if col_sum > 0 else 0\n",
    "    \n",
    "pcmesh = ax[0].pcolormesh(t3pad_mesh,pangle,epad_med_norm,cmap='turbo',vmin=0,vmax=1,shading='gouraud')\n",
    "\n",
    "# pcmesh = ax[0].pcolormesh(t3pad_mesh,pangle,(electronflux[:,:,4]),cmap='turbo',vmin=cmap_min,vmax=cmap_max,shading='gouraud')\n",
    "cbar=fig.colorbar(pcmesh, ax=ax[0])\n",
    "cbar.set_label('number flux', rotation=90)\n",
    "\n",
    "centroids_epad = np.ma.average(pangle,weights=epad_med,axis=1)\n",
    "ax[0].plot(t3pad,centroids_epad,color='k',ls='--',lw=5)\n",
    "\n",
    "# for i in range(len(strahl_regions)):\n",
    "#     colors_list = ['purple','orange','magenta']\n",
    "#     ax[0].fill_betweenx([0,200],t3pad[strahl_contig_inds[i][0]],t3pad[strahl_contig_inds[i][1]],color=colors_list[strahl_regions[i][0]],alpha=0.3)\n",
    "\n",
    "p_range = [0,t3pad.size]\n",
    "ax[1].scatter(t3pad[p_range[0]:p_range[1]],phi_B_median[p_range[0]:p_range[1]])\n",
    "for i in rot_mids:\n",
    "    ax[1].scatter(t3pad[i],phi_B_median[i],c='orange',s=30)\n",
    "for (i,j) in rot_bounds:\n",
    "    ax[1].scatter(t3pad[i],phi_B_median[i],c='green',s=30)\n",
    "    ax[1].scatter(t3pad[i],phi_B_median[j],c='green',s=30)\n",
    "# for i in range(len(hcs_regions)):\n",
    "#     ax[0].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "#     ax[1].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "#     ax[2].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "#     ax[3].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "#     ax[4].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "#     ax[5].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "\n",
    "# for i in hcs_walls:\n",
    "#     ax[0].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "#     ax[1].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "#     ax[2].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "#     ax[3].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "#     ax[4].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "#     ax[5].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "\n",
    "ax[0].set_title('PAD (column normalized)')\n",
    "ax[0].set_ylabel(r'$\\degree$')\n",
    "ax[0].set_yticks([0,45,90,135,180])\n",
    "ax[1].set_title(r'$\\phi_B$')\n",
    "ax[1].set_ylabel(r'$\\degree$')\n",
    "ax[1].set_yticks([0,90,180,270,360])\n",
    "ax[2].set_title(r'$\\theta_B$')\n",
    "ax[2].set_ylabel(r'$\\degree$')\n",
    "ax[2].set_yticks([0,90,180,270,360])\n",
    "\n",
    "tick_locs,tick_labels = tasteful_ticks(t3pad,num_ticks=5)\n",
    "ax[0].set_xticks([])\n",
    "ax[1].set_xticks([])\n",
    "ax[2].set_xticks([])\n",
    "ax[3].set_xticks([])\n",
    "ax[4].set_xticks([])\n",
    "ax[5].set_xticks(tick_locs)\n",
    "\n",
    "ax[5].set_xticklabels(tick_labels)\n",
    "\n",
    "ax[2].scatter(t3pad,theta_B_median)\n",
    "\n",
    "ax[3].plot(tB,Bmag,c='k',label=r'$B$')\n",
    "ax[3].plot(tB,Bx,c='blue',label=r'$B_x$')\n",
    "ax[3].plot(tB,Bz,c='green',label=r'$B_z$')\n",
    "ax[3].set_title('B')\n",
    "ax[3].legend(frameon=False)\n",
    "\n",
    "ax[4].plot(t3pm,ni)\n",
    "ax[4].set_ylim([0,30])\n",
    "ax[4].set_title('proton density')\n",
    "\n",
    "ax[5].plot(t3pm,Vmag)\n",
    "ax[5].set_title('speed')\n",
    "ax[5].set_ylim([0,1000])\n",
    "\n",
    "plt.savefig('hcs params 082525, days={}.pdf'.format(days),format='pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot wave locations\n",
    "\n",
    "# ## 0. Import\n",
    "# try:\n",
    "#     d_temp = pd.read_csv('/Volumes/T9/mva params/mva_params_{}_{}_081425.csv'.format(2024,12))\n",
    "    \n",
    "#     preds_list = d_temp.values[:,-1]  \n",
    "#     date_starts = d_temp.values[:,0]\n",
    "      \n",
    "# except:\n",
    "#     print('mva param error: {} {}'.format(2024,12))\n",
    "\n",
    "## 1. Start and end dates for each interval in terms of t3pad\n",
    "# start_epochs = [cdf.cdfepoch.compute_epoch([int(date_starts[i][0:4]),int(date_starts[i][5:7]),int(date_starts[i][8:10]),\n",
    "#                                             int(date_starts[i][11:13]),int(date_starts[i][14:16]),int(date_starts[i][17:19]),\n",
    "#                                             int(date_starts[i][20:])]) for i in range(len(date_starts))]\n",
    "\n",
    "# start_tB = np.argmax(tB > start_epochs[0])\n",
    "end_tB = np.argmax(tB > start_epochs[-1] + 66)\n",
    "\n",
    "\n",
    "## 2. Plot locations of wave interval midpoints on t3pad\n",
    "\n",
    "# preds_arr = np.array(preds_list)\n",
    "# good_inds = np.where(preds_arr > 0.95)\n",
    "\n",
    "tick_locs,tick_labels = tasteful_ticks(tB,num_ticks=5)\n",
    "\n",
    "t_vals = np.zeros(tB.size)\n",
    "\n",
    "for k in good_inds:\n",
    "    t_vals[start_epochs[k]:start_epochs[k] + 66] = 1\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "ax.plot(tB,t_vals)\n",
    "\n",
    "ax.set_xticks(tick_locs)\n",
    "ax.set_xticklabels(tick_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b73234",
   "metadata": {},
   "outputs": [],
   "source": [
    "### column normalization of epads\n",
    "epad = electronflux[:,:,4]\n",
    "epad_med = scipy.signal.medfilt2d(epad,kernel_size=(med_filter_len,1))\n",
    "    \n",
    "epad_norm = np.zeros(epad.shape)\n",
    "epad_med_norm = np.zeros(epad.shape)\n",
    "for k in range(epad.shape[0]):\n",
    "    epad_ma = np.ma.array(epad[k,:],mask=epad[k,:] == 0)\n",
    "    col_sum = np.ma.sum(epad[k,:])\n",
    "    epad_norm[k,:] = epad_ma/col_sum if col_sum > 0 else 0\n",
    "\n",
    "    epad_ma = np.ma.array(epad_med[k,:],mask=epad_med[k,:] == 0)\n",
    "    col_sum = np.ma.sum(epad_med[k,:])\n",
    "    epad_med_norm[k,:] = epad_ma/col_sum if col_sum > 0 else 0\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(2,1,figsize=(12,12),layout='compressed')\n",
    "\n",
    "t3pad_mesh = np.expand_dims(t3pad,axis=0)\n",
    "t3pad_mesh = np.repeat(t3pad_mesh,8,axis=0).T\n",
    "\n",
    "pcmesh = ax[0].pcolormesh(t3pad_mesh,pangle,epad_norm,cmap='turbo',norm=colors.LogNorm(vmin=1e-2,vmax=1),shading='gouraud')\n",
    "cbar=fig.colorbar(pcmesh, ax=ax[0])\n",
    "ax[0].set_title('unfiltered col normed PAD')\n",
    "\n",
    "pcmesh = ax[1].pcolormesh(t3pad_mesh,pangle,epad_med_norm,cmap='turbo',norm=colors.LogNorm(vmin=1e-2,vmax=1),shading='gouraud')\n",
    "cbar=fig.colorbar(pcmesh, ax=ax[1])\n",
    "ax[1].set_title('median filtered col normed PAD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06941f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute metric: distance from HCS\n",
    "\n",
    "## For each interval midpoint, compute shortest time delta to hcs_flag == 1\n",
    "\n",
    "## 1. Compute hcs_loc at each month\n",
    "for y in range(2024,2026):\n",
    "    for m in range(1,13):\n",
    "        \n",
    "        date = [y,m,15,0,0,0]\n",
    "\n",
    "        days = 25\n",
    "        hours = 0\n",
    "        minutes = 0\n",
    "        date_e = [date[0] ,date[1], date[2] + days, date[3] + hours, date[4] + minutes, date[5]]\n",
    "\n",
    "        key_list = []\n",
    "        keylist_list = []\n",
    "\n",
    "        # lists of rich text strings for plot labels \n",
    "        label_list = []\n",
    "        labellist_list = []\n",
    "\n",
    "        kB = 1.38e-23\n",
    "        mp = 1.67e-27\n",
    "\n",
    "        try:\n",
    "            tB,Bmagt,Bxt,Byt,Bzt = mfi_varsnip(date,hours = hours,days = days,dateloc='mid',)\n",
    "            phi_B = np.degrees(np.arctan2(Bxt,Byt)) + 180\n",
    "        except:\n",
    "            print('Error: MFI')\n",
    "            pass    \n",
    "        try:\n",
    "            t3pad,electronflux,pangle = thrdp_varsnip(date,hours = hours,days = days,dateloc='mid',isPAD=True)\n",
    "            electronflux = np.nan_to_num(electronflux,0)\n",
    "            # ensure pangle uses \n",
    "            pangle_nan_fill = np.linspace(0,180,8)\n",
    "            for i in range(pangle.shape[0]):\n",
    "                if np.isnan(pangle[i]).any():\n",
    "                    for j in range(8):\n",
    "                        if np.isnan(pangle[i,j]):\n",
    "                            pangle[i,j] = pangle_nan_fill[j]\n",
    "\n",
    "        except:\n",
    "            print('Error: 3dp PADs')\n",
    "            continue\n",
    "\n",
    "        # for each month, access start and end info\n",
    "        # \n",
    "        try:\n",
    "            d_temp = pd.read_csv('/Volumes/Seagate/Paper 2/data by month/sw params by month/sw_params_{}_{}_123024.csv'.format(y,m))\n",
    "            date_starts = d_temp.values[:,0]\n",
    "            date_ends = d_temp.values[:,1]\n",
    "        except:\n",
    "            print('sw param error: {} {}'.format(y,m))\n",
    "            continue\n",
    "        try:\n",
    "            d_temp = pd.read_csv('/Volumes/Seagate/Paper 2/data by month/mva params by month/mva_params_{}_{}_123024.csv'.format(y,m))\n",
    "            preds_list = d_temp.values[:,-1]        \n",
    "        except:\n",
    "            print('mva param error: {} {}'.format(y,m))\n",
    "            continue\n",
    "\n",
    "    # 2. for each month, compute distance between interval midpoints and nearest hcs region\n",
    "\n",
    "        start_epochs = [cdf.cdfepoch.compute_epoch([int(date_starts[i][0:4]),int(date_starts[i][5:7]),int(date_starts[i][8:10]),\n",
    "                                                   int(date_starts[i][11:13]),int(date_starts[i][14:16]),int(date_starts[i][17:19]),\n",
    "                                                   int(date_starts[i][20:])]) for i in range(len(date_starts))]\n",
    "        end_epochs = [cdf.cdfepoch.compute_epoch([int(date_ends[i][0:4]),int(date_ends[i][5:7]),int(date_ends[i][8:10]),\n",
    "                                                   int(date_ends[i][11:13]),int(date_ends[i][14:16]),int(date_ends[i][17:19]),\n",
    "                                                   int(date_ends[i][20:])]) for i in range(len(date_ends))]\n",
    "        t_mids = [0.5*(start_epochs[i] + end_epochs[i]) for i in range(len(start_epochs))]\n",
    "\n",
    "        start_tpad = np.argmax(t3pad > t_mids[0])\n",
    "        end_tpad = np.argmax(t3pad > t_mids[-1]) - 1\n",
    "\n",
    "        start_tB = np.argmax(tB > t_mids[0])\n",
    "        end_tB = np.argmax(tB > t_mids[-1]) - 1\n",
    "\n",
    "        # for each month, compute hcs_bounds (locations of )\n",
    "\n",
    "        hcs_sb, hcs_bounds = hcs_loc(t3pad,tB,electronflux,phi_B,med_filter_len=49,return_bounds=True)\n",
    "        hcs_walls = strahl_walls(electronflux,pangle,region_inds=hcs_bounds)\n",
    "        hcs_bounds = [[hcs_bounds[k][0],hcs_bounds[k][1]] for k in hcs_walls]\n",
    "        \n",
    "        # distance metric\n",
    "        dist_from_hcs = -1 * np.ones(len(t_mids))\n",
    "        last_mid = t_mids[-1]\n",
    "        \n",
    "        ## split into two pieces\n",
    "        # A. If we are in hcs, dist_from_hcs = 0\n",
    "        k = 0 # index of t_mids\n",
    "        for (i_s,i_e) in hcs_bounds:\n",
    "\n",
    "            # ensure tpad times are within desired range\n",
    "            if i_e > start_tpad and i_s < end_tpad:\n",
    "                \n",
    "                hcs_subint = t3pad[i_s:i_e]\n",
    "\n",
    "                while t_mids[k] < hcs_subint[-1]:\n",
    "\n",
    "                    if t_mids[k] > hcs_subint[0]:\n",
    "                        dist_from_hcs[k] = 0\n",
    "\n",
    "                    if k < len(t_mids) - 1:\n",
    "                        k += 1\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "        # B. If we are out of hcs, dist_from_hcs = min(dist from hcs bounds)\n",
    "        leftover_inds = np.where(dist_from_hcs < 0)[0]\n",
    "        for j in leftover_inds:\n",
    "            flattened_hcs_t = t3pad[np.concatenate(hcs_bounds)]\n",
    "            dist_from_hcs[j] = np.min(np.absolute(t_mids[j] - flattened_hcs_t))/1000/3600\n",
    "\n",
    "        ### 3. Save to cdf\n",
    "        with open('/Users/sfordin/Documents/Paper 2/sw params/hcs_dist_{}_{}_072525.csv'.format(y,m),'a') as fd:\n",
    "            fd.write('Start_date,End_date,\\\n",
    "            hcs_dist_h' + \"\\n\")\n",
    "            for i in range(len(t_mids)):\n",
    "\n",
    "                event_string = ','.join(map(str,[date_starts[i],date_ends[i],\n",
    "                                                 dist_from_hcs[i].astype('float32')]))\n",
    "                fd.write(event_string + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dddf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot distance from hcs\n",
    "good_inds = np.where(preds_list > 0.95)[0]\n",
    "\n",
    "fig,ax=plt.subplots(3,1,figsize=(12,12))\n",
    "ax[0].hist(dist_from_hcs,bins=30,density=True,color='blue')\n",
    "ax[0].hist(dist_from_hcs[good_inds],bins=30,density=True,color='red',alpha=0.5)\n",
    "ax[0].set_ylabel('pdf')\n",
    "ax[0].set_title('')\n",
    "\n",
    "hcs_len = 0\n",
    "for (i,j) in hcs_bounds:\n",
    "    hcs_len += j - i\n",
    "print('{:.2%}'.format(hcs_len/t3pad.size) + ' of all intervals are in hcs')\n",
    "\n",
    "rat_hist = np.histogram(dist_from_hcs[good_inds],bins=30)[0]/np.histogram(dist_from_hcs,bins=30)[0]\n",
    "bins = np.histogram(dist_from_hcs,bins=30)[1]\n",
    "bin_widths = np.diff(bins)\n",
    "ax[1].bar(bins[:-1] + bin_widths/2,rat_hist,width=bin_widths,color='purple')\n",
    "ax[1].axhline(good_inds.size/len(preds_list))\n",
    "ax[1].set_ylabel('ratio')\n",
    "\n",
    "\n",
    "ax[2].plot(t_mids,dist_from_hcs)\n",
    "tick_params = tasteful_ticks(t_mids)\n",
    "ax[2].set_xticks(tick_params[0])\n",
    "ax[2].set_xticklabels(tick_params[1])\n",
    "\n",
    "ax[2].set_xlabel('hours from hcs')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.diff(tB_solo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ebe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute wavelet\n",
    "### Load data as a dataframe with columns Bx,By,Bz and indexed by time\n",
    "\n",
    "start_t = cdf.cdfepoch.compute_epoch(date)\n",
    "end_t = cdf.cdfepoch.compute_epoch(date_e)\n",
    "t_dt = cdf.cdfepoch.breakdown(tB_solo)\n",
    "\n",
    "t_dt = [dt.datetime(year=t_dt[i][0],month=t_dt[i][1],day = t_dt[i][2],hour=t_dt[i][3],minute=t_dt[i][4],second=t_dt[i][5],microsecond= t_dt[i][6]*1000) for i in range(len(t_dt))]\n",
    "    \n",
    "# delta_t = 1/11 # Wind cadence\n",
    "delta_t = 1/16 # SolO cadence\n",
    "\n",
    "f_range = [5e-2,3]\n",
    "f_n = 32\n",
    "\n",
    "start = np.argmax(tB_solo > start_t)\n",
    "end = np.argmax(tB_solo < end_t)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=np.vstack([Bx_solo,By_solo,Bz_solo]).T,columns=['Bx','By','Bz'])\n",
    "print(df)\n",
    "if df['Bx'].isna().sum()/len(df.Bx)<=0.1 and df['By'].isna().sum()/len(df.By)<=0.1 and df['Bz'].isna().sum()/len(df.Bz)<=0.1 :\n",
    "\n",
    "    df=df.interpolate()\n",
    "    df=df.dropna()\n",
    "\n",
    "\n",
    "    time_axis = np.linspace(0, df.Bx.shape[0], df.Bx.shape[0])\n",
    "    mu_0 = 4*np.pi*1e-7#N/A^2=kg.m/(s^2.A^2)\n",
    "    m_proton=1.673*1e-27#kg\n",
    "    \n",
    "    rho = 7*m_proton*1e6*5/6 # kg m^{-3} see Good et al. 2022 MNRAS for more details\n",
    "    \n",
    "    # playing around with random values\n",
    "    vx_n = np.repeat(400*1e3,df.Bx.shape[0]) # m/s\n",
    "    vy_n = np.repeat(30*1e3,df.Bx.shape[0]) # m/s\n",
    "    vz_n = np.repeat(-40*1e3,df.Bx.shape[0]) # m/s\n",
    "    \n",
    "    # tem = tem*1e3 # m s^{-1}\n",
    "    \n",
    "    bx_n = (1e-9*df.Bx)/np.sqrt(mu_0*rho) # m/s\n",
    "    by_n = (1e-9*df.By)/np.sqrt(mu_0*rho) # m/s\n",
    "    bz_n = (1e-9*df.Bz)/np.sqrt(mu_0*rho) # m/s\n",
    "    \n",
    "    radi=180/(4*np.arctan(1))\n",
    "    ph=radi*np.arctan2(df.By,df.Bx)\n",
    "    gg=np.where((ph < 0)); \n",
    "    for i in gg:\n",
    "        ph[i]=radi*np.arctan2(df.By[i],df.Bx[i])+360.\n",
    "    \n",
    "    z_plusx = vx_n+bx_n\n",
    "    z_plusy = vy_n+by_n\n",
    "    z_plusz = vz_n+bz_n\n",
    "\n",
    "    z_minusx=vx_n-bx_n\n",
    "    z_minusy=vy_n-by_n\n",
    "    z_minusz=vz_n-bz_n\n",
    "    #select the inertial range (1e-4-1e-2 hz), dt=1min=60sec\n",
    "    # print('uo')\n",
    "    my_wavelet2go = Wavelet2Go(f_n=f_n, f_min=f_range[0], f_max=f_range[1], dt=delta_t) # Telloni et al 2020\n",
    "    yticks,ytickfreqs = my_wavelet2go.get_y_ticks(reduction_to=5)\n",
    "    xticks,xtickfreqs = my_wavelet2go.get_x_ticks(reduction_to=int(60*(60/delta_t)/2),data=df.Bx)\n",
    "    cwtbfx, freqs = my_wavelet2go.perform_transform(df.Bx-np.mean(df.Bx))\n",
    "    cwtbfy, freqs = my_wavelet2go.perform_transform(df.By-np.mean(df.By))\n",
    "    cwtbfz, freqs = my_wavelet2go.perform_transform(df.Bz-np.mean(df.Bz))   \n",
    "    eb_fluc=(abs(cwtbfx)**2+abs(cwtbfy)**2+abs(cwtbfz)**2)\n",
    "\n",
    "\n",
    "\n",
    "    cwtbx, freqs = my_wavelet2go.perform_transform(df.Bx)\n",
    "    cwtby, freqs = my_wavelet2go.perform_transform(df.By)\n",
    "    cwtbz, freqs = my_wavelet2go.perform_transform(df.Bz)\n",
    "\n",
    "    \n",
    "    a=2*(np.conj(cwtby)*cwtbz).imag\n",
    "    b=(abs(cwtby)**2+abs(cwtbz)**2)\n",
    "    a=my_wavelet2go.mask_invalid_data(a, fill_value=0)\n",
    "    b=my_wavelet2go.mask_invalid_data(b, fill_value=0)\n",
    "    sigm=a/b #######                                         magnetic helicity\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"not possible\")\n",
    "\n",
    "#############################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d97102",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the wavelet transform\n",
    "\n",
    "## 1. Initialize two different time series\n",
    "t1 = [50000,100000]\n",
    "t2 = [60000,110000]\n",
    "\n",
    "# delta_t = 1/11 # Wind cadence\n",
    "delta_t = 1/16 # SolO cadence\n",
    "\n",
    "f_range = [5e-2,8]\n",
    "f_n = 128\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(data=np.vstack([Bx_solo[t1[0]:t1[1]],By_solo[t1[0]:t1[1]],Bz_solo[t1[0]:t1[1]]]).T,columns=['Bx','By','Bz'])\n",
    "df2 = pd.DataFrame(data=np.vstack([Bx_solo[t2[0]:t2[1]],By_solo[t2[0]:t2[1]],Bz_solo[t2[0]:t2[1]]]).T,columns=['Bx','By','Bz'])\n",
    "\n",
    "eb_fluc = []\n",
    "sigm = []\n",
    "\n",
    "for df in [df1,df2]:\n",
    "    if df['Bx'].isna().sum()/len(df.Bx)<=0.1 and df['By'].isna().sum()/len(df.By)<=0.1 and df['Bz'].isna().sum()/len(df.Bz)<=0.1 :\n",
    "\n",
    "        df=df.interpolate()\n",
    "        df=df.dropna()\n",
    "\n",
    "        time_axis = np.linspace(0, df.Bx.shape[0], df.Bx.shape[0])\n",
    "        mu_0 = 4*np.pi*1e-7#N/A^2=kg.m/(s^2.A^2)\n",
    "        m_proton=1.673*1e-27#kg\n",
    "        \n",
    "        rho = 7*m_proton*1e6*5/6 # kg m^{-3} see Good et al. 2022 MNRAS for more details\n",
    "        \n",
    "        # playing around with random values\n",
    "        vx_n = np.repeat(400*1e3,df.Bx.shape[0]) # m/s\n",
    "        vy_n = np.repeat(30*1e3,df.Bx.shape[0]) # m/s\n",
    "        vz_n = np.repeat(-40*1e3,df.Bx.shape[0]) # m/s\n",
    "        \n",
    "        # tem = tem*1e3 # m s^{-1}\n",
    "        \n",
    "        bx_n = (1e-9*df.Bx)/np.sqrt(mu_0*rho) # m/s\n",
    "        by_n = (1e-9*df.By)/np.sqrt(mu_0*rho) # m/s\n",
    "        bz_n = (1e-9*df.Bz)/np.sqrt(mu_0*rho) # m/s\n",
    "        \n",
    "        radi=180/(4*np.arctan(1))\n",
    "        ph=radi*np.arctan2(df.By,df.Bx)\n",
    "        gg=np.where((ph < 0)); \n",
    "        for i in gg:\n",
    "            ph[i]=radi*np.arctan2(df.By[i],df.Bx[i])+360.\n",
    "        \n",
    "        z_plusx = vx_n+bx_n\n",
    "        z_plusy = vy_n+by_n\n",
    "        z_plusz = vz_n+bz_n\n",
    "\n",
    "        z_minusx=vx_n-bx_n\n",
    "        z_minusy=vy_n-by_n\n",
    "        z_minusz=vz_n-bz_n\n",
    "        #select the inertial range (1e-4-1e-2 hz), dt=1min=60sec\n",
    "        # print('uo')\n",
    "        my_wavelet2go = Wavelet2Go(f_n=f_n, f_min=f_range[0], f_max=f_range[1], dt=delta_t) # Telloni et al 2020\n",
    "        yticks,ytickfreqs = my_wavelet2go.get_y_ticks(reduction_to=5)\n",
    "        xticks,xtickfreqs = my_wavelet2go.get_x_ticks(reduction_to=int(60*(60/delta_t)/2),data=df.Bx)\n",
    "        cwtbfx, freqs = my_wavelet2go.perform_transform(df.Bx-np.mean(df.Bx))\n",
    "        cwtbfy, freqs = my_wavelet2go.perform_transform(df.By-np.mean(df.By))\n",
    "        cwtbfz, freqs = my_wavelet2go.perform_transform(df.Bz-np.mean(df.Bz))   \n",
    "\n",
    "        eb_fluc.append(abs(cwtbfx)**2+abs(cwtbfy)**2+abs(cwtbfz)**2)\n",
    "\n",
    "        cwtbx, freqs = my_wavelet2go.perform_transform(df.Bx)\n",
    "        cwtby, freqs = my_wavelet2go.perform_transform(df.By)\n",
    "        cwtbz, freqs = my_wavelet2go.perform_transform(df.Bz)\n",
    "\n",
    "        \n",
    "        a=2*(np.conj(cwtby)*cwtbz).imag\n",
    "        b=(abs(cwtby)**2+abs(cwtbz)**2)\n",
    "        a=my_wavelet2go.mask_invalid_data(a, fill_value=0)\n",
    "        b=my_wavelet2go.mask_invalid_data(b, fill_value=0)\n",
    "        sigm.append(a/b) #######                                         magnetic helicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3058e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345eb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare shifted wavelet outputs\n",
    "\n",
    "fig,ax=plt.subplots(6,1,figsize=(6,12))\n",
    "\n",
    "## 1. First wavelet\n",
    "pcm1=ax[0].pcolormesh(df1.index[int(t2[0]-t1[0]):],freqs,(eb_fluc[0][:,int(t2[0]-t1[0]):]),norm=colors.LogNorm(vmin=1e-6,vmax=1e1), cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm1, ax=ax[0])\n",
    "cbar.set_label(r'$E_{\\delta B}$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB_solo[t1[0]:t1[1]])\n",
    "ax[0].set_ylabel(r'$E_{\\delta B}$')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xticklabels(ticklabels)\n",
    "ax[0].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "## 2. Second wavelet\n",
    "pcm1=ax[1].pcolormesh(df2.index[:-int(t2[0]-t1[0])],freqs,(eb_fluc[1][:,:-int(t2[0]-t1[0])]),norm=colors.LogNorm(vmin=1e-6,vmax=1e1), cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm1, ax=ax[1])\n",
    "cbar.set_label(r'$E_{\\delta B}$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB_solo[t2[0]:t2[1]])\n",
    "ax[1].set_ylabel(r'$E_{\\delta B}$')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xticklabels(ticklabels)\n",
    "ax[1].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "## 3. Difference of first and second wavelets normalized by average wavelet power\n",
    "pcm1=ax[2].pcolormesh(df2.index[:-int(t2[0]-t1[0])],freqs,2*(eb_fluc[1][:,:-int(t2[0]-t1[0])] - eb_fluc[0][:,int(t2[0]-t1[0]):])/(eb_fluc[1][:,:-int(t2[0]-t1[0])] + eb_fluc[0][:,int(t2[0]-t1[0]):]), norm=colors.LogNorm(vmin=1e-5,vmax=1e-2),cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm1, ax=ax[2])\n",
    "cbar.set_label(r'$E_{\\delta B}$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB_solo[t1[0]:t1[1]])\n",
    "ax[2].set_ylabel(r'$E_{\\delta B}$')\n",
    "ax[2].set_yscale('log')\n",
    "ax[2].set_xticklabels(ticklabels)\n",
    "ax[2].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "## 4. First helicity\n",
    "pcm1=ax[3].pcolormesh(df1.index[int(t2[0]-t1[0]):],freqs,(sigm[0][:,int(t2[0]-t1[0]):]),vmin=-1,vmax=1, cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm1, ax=ax[3])\n",
    "cbar.set_label(r'$\\sigma_B$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB_solo[t1[0]:t1[1]])\n",
    "ax[3].set_ylabel(r'$\\sigma_B$')\n",
    "ax[3].set_xticklabels(ticklabels)\n",
    "ax[3].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "## 2. Second helicity\n",
    "pcm1=ax[4].pcolormesh(df2.index[:-int(t2[0]-t1[0])],freqs,(sigm[1][:,:-int(t2[0]-t1[0])]),vmin=-1,vmax=1, cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm1, ax=ax[4])\n",
    "cbar.set_label(r'$\\sigma_B$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB_solo[t2[0]:t2[1]])\n",
    "ax[4].set_ylabel(r'$\\sigma_B$')\n",
    "ax[4].set_xticklabels(ticklabels)\n",
    "ax[4].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "## 3. Difference of first and second helicities normalized by average wavelet power\n",
    "pcm1=ax[5].pcolormesh(df2.index[:-int(t2[0]-t1[0])],freqs,2*(sigm[1][:,:-int(t2[0]-t1[0])] - sigm[0][:,int(t2[0]-t1[0]):])/(sigm[1][:,:-int(t2[0]-t1[0])] + sigm[0][:,int(t2[0]-t1[0]):]), norm=colors.LogNorm(vmin=1e-5,vmax=1e-2),cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm1, ax=ax[5])\n",
    "cbar.set_label(r'$\\sigma_B$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB_solo[t1[0]:t1[1]])\n",
    "ax[5].set_ylabel(r'$\\sigma_B$')\n",
    "ax[5].set_xticklabels(ticklabels)\n",
    "ax[5].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "c = np.array([7,8,9])\n",
    "print(np.vstack((a,b,c))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a230b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a68bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.diff(tB_solo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1149a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot long interval of SolO magnetic field using wavelet2Long\n",
    "\n",
    "B_for_wavelet = np.vstack((Bx_solo,By_solo,Bz_solo))\n",
    "\n",
    "delta_t = 1/8\n",
    "t_len = int(120*60*1/delta_t)\n",
    "full_t_len = np.arange(0,tB_solo.size,1)\n",
    "ratio_COI = 0.2\n",
    "t_ind_chunks = chunk(full_t_len,chunksize = t_len,stepsize = int(t_len*(1-2*ratio_COI)))\n",
    "\n",
    "fig,ax=plt.subplots(2,1,figsize=(20,10))\n",
    "for k in range(len(t_ind_chunks)):\n",
    "    \n",
    "    t_range = (t_ind_chunks[k][0],t_ind_chunks[k][-1]) ### (first,last) indices of time for full wavelet\n",
    "\n",
    "    t_plot,freqs_plot,eb_fluc_plot,sigm_plot = wavelet2Long(t_range,B_for_wavelet,f_n = 128,f_min=1e-2,f_max=4,delta_t=delta_t)\n",
    "    \n",
    "    ## truncate wavelet transforms to correct index range (eb_fluc+sigm have same length as t_range, but different starting/ending index)\n",
    "    pcm1=ax[0].pcolormesh(full_t_len[t_plot[0]:t_plot[1]],freqs_plot,(eb_fluc_plot[:,t_plot[0]-t_range[0]:t_plot[1]-t_range[0]]),norm=colors.LogNorm(vmin=1e-6,vmax=1e1), cmap='jet',rasterized=True)\n",
    "    pcm2=ax[1].pcolormesh(full_t_len[t_plot[0]:t_plot[1]],freqs_plot,(sigm_plot[:,t_plot[0]-t_range[0]:t_plot[1]-t_range[0]]),vmin=-1,vmax=1, cmap='jet',rasterized=True)\n",
    "    if k % 20 is 0:\n",
    "        print('Complete: ' + str(t_plot) + ' from total length ' + str(full_t_len))\n",
    "\n",
    "cbar=fig.colorbar(pcm1, ax=ax[0])\n",
    "cbar.set_label(r'$E_{\\delta B}$',rotation=90)\n",
    "cbar=fig.colorbar(pcm2, ax=ax[1])\n",
    "\n",
    "cbar.set_label(r'$\\sigma_M$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB_solo[0:t_range[1]])\n",
    "\n",
    "ax[0].set_ylabel(r'$E_{\\delta B}$')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax[0].set_xticklabels(ticklabels)\n",
    "ax[1].set_ylabel(r'$\\sigma_M$')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xticklabels(ticklabels)\n",
    "ax[1].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "plt.savefig('/Users/sfordin/Documents/Science-Projects/01-psp-wind-conjunction/figures/fig wavelets SolO.pdf',format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot long interval of Wind magnetic field using wavelet2Long\n",
    "\n",
    "B_for_wavelet = np.vstack((Bx,By,Bz))\n",
    "\n",
    "delta_t = 1/11\n",
    "t_len = int(120*60*1/delta_t)\n",
    "full_t_len = np.arange(0,tB.size,1)\n",
    "ratio_COI = 0.2\n",
    "t_ind_chunks = chunk(full_t_len,chunksize = t_len,stepsize = int(t_len*(1-2*ratio_COI)))\n",
    "\n",
    "fig,ax=plt.subplots(2,1,figsize=(20,10))\n",
    "\n",
    "for k in range(len(t_ind_chunks)):\n",
    "\n",
    "    t_range = (t_ind_chunks[k][0],t_ind_chunks[k][-1]) ### (first,last) indices of time for full wavelet\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        t_plot,freqs_plot,eb_fluc_plot,sigm_plot = wavelet2Long(t_range,B_for_wavelet,f_n = 128,f_min=1e-2,f_max=5.5,delta_t = delta_t)\n",
    "    \n",
    "    ## truncate wavelet transforms to correct index range (eb_fluc+sigm have same length as t_range, but different starting/ending index)\n",
    "    pcm1=ax[0].pcolormesh(full_t_len[t_plot[0]:t_plot[1]],freqs_plot,(eb_fluc_plot[:,t_plot[0]-t_range[0]:t_plot[1]-t_range[0]]),norm=colors.LogNorm(vmin=1e-6,vmax=1e1), cmap='jet',rasterized=True)\n",
    "    pcm2=ax[1].pcolormesh(full_t_len[t_plot[0]:t_plot[1]],freqs_plot,(sigm_plot[:,t_plot[0]-t_range[0]:t_plot[1]-t_range[0]]),vmin=-1,vmax=1, cmap='jet',rasterized=True)\n",
    "    if k % 20 is 0:\n",
    "        print('Complete: ' + str(t_plot) + ' from total length ' + str(full_t_len.size) + ', ' + str(time.time()))\n",
    "cbar=fig.colorbar(pcm1, ax=ax[0])\n",
    "cbar.set_label(r'$E_{\\delta B}$',rotation=90)\n",
    "\n",
    "cbar=fig.colorbar(pcm2, ax=ax[1])\n",
    "cbar.set_label(r'$\\sigma_M$',rotation=90)\n",
    "\n",
    "ticklocs,ticklabels = tasteful_ticks(tB[0:t_range[1]])\n",
    "\n",
    "ax[0].set_ylabel(r'$E_{\\delta B}$')\n",
    "# ax[0].set_xticks(ticklocs)\n",
    "ax[0].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax[0].set_xticklabels(ticklabels)\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "ax[1].set_ylabel(r'$\\sigma_M$')\n",
    "# ax[1].set_xticks(ticklocs)\n",
    "ax[1].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax[1].set_xticklabels(ticklabels)\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "plt.savefig('/Users/sfordin/Documents/Science-Projects/01-psp-wind-conjunction/figures/fig wavelets Wind.png',format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc72cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot wavelet\n",
    "\n",
    "\n",
    "### Plotting time\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "\n",
    "# med_filter_len = 49\n",
    "\n",
    "# phi_B_ds = resample(phi_B,new_times=t3pad,times=tB)[1] # resample phi_B at same cadence as PADs\n",
    "# phi_B_median = scipy.signal.medfilt(phi_B_ds,kernel_size = med_filter_len)\n",
    "\n",
    "# theta_B_ds = resample(theta_B,new_times=t3pad,times=tB)[1] # resample phi_B at same cadence as PADs\n",
    "# theta_B_median = scipy.signal.medfilt(theta_B_ds,kernel_size = med_filter_len)\n",
    "\n",
    "# hcs_sb,hcs_regions = hcs_loc(t3pad,tB,electronflux,phi_B,med_filter_len=med_filter_len,buffer_range=0,return_bounds=True)\n",
    "# hcs_walls = strahl_walls(electronflux,pangle,region_inds=hcs_regions)\n",
    "\n",
    "# rot_bounds,rot_mids = autochord(phi_B_median)\n",
    "\n",
    "# # for j in range(len(rot_times)):\n",
    "# #     plt.scatter(rot_bounds[j][0],phi_B_median[rot_bounds[j][0]],c='green',s=100)\n",
    "# #     plt.scatter(rot_bounds[j][1],phi_B_median[rot_bounds[j][1]],c='green',s=100)\n",
    "# t3pad_mesh = np.expand_dims(t3pad,axis=0)\n",
    "# t3pad_mesh = np.repeat(t3pad_mesh,8,axis=0).T\n",
    "# cmap_min = np.max([np.ma.min(electronflux[:,:,4][electronflux[:,:,4] > 0]),1e3])\n",
    "# cmap_max = np.min([np.ma.max(electronflux[:,:,4][electronflux[:,:,4] > 0]),4e5])\n",
    "    \n",
    "# epad_norm = np.zeros(epad.shape)\n",
    "# epad_med_norm = np.zeros(epad.shape)\n",
    "# for k in range(epad.shape[0]):\n",
    "#     epad_ma = np.ma.array(epad[k,:],mask=epad[k,:] == 0)\n",
    "#     col_sum = np.ma.sum(epad[k,:])\n",
    "#     epad_norm[k,:] = epad_ma/col_sum if col_sum > 0 else 0\n",
    "\n",
    "#     epad_ma = np.ma.array(epad_med[k,:],mask=epad_med[k,:] == 0)\n",
    "#     col_sum = np.ma.sum(epad_med[k,:])\n",
    "#     epad_med_norm[k,:] = epad_ma/col_sum if col_sum > 0 else 0\n",
    "    \n",
    "\n",
    "# # plot_list = ['Bmag','phi_B','ni','Vmag']\n",
    "# plot_list = []\n",
    "# n = len(plot_list)\n",
    "ticklocs,ticklabels = tasteful_ticks(t3pad)\n",
    "\n",
    "fig,ax=plt.subplots(3,1,figsize=(10,8),layout='compressed')\n",
    "\n",
    "# wavelet\n",
    "pcm1=ax[0].pcolormesh(df.index,freqs,(eb_fluc),norm=colors.LogNorm(vmin=1e-6,vmax=1e1), cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm1, ax=ax[0])\n",
    "cbar.set_label(r'$E_{\\delta B}$',rotation=90)\n",
    "ticklocs,ticklabels = tasteful_ticks(tB)\n",
    "ax[0].set_ylabel(r'$E_{\\delta B}$')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax[0].set_xticklabels(ticklabels)\n",
    "\n",
    "# sigm\n",
    "pcm2=ax[1].pcolormesh(df.index,freqs,(sigm),vmin=-1,vmax=1, cmap='jet',rasterized=True)\n",
    "cbar=fig.colorbar(pcm2, ax=ax[1])\n",
    "cbar.set_label(r'$\\sigma_m$', rotation=90)\n",
    "ax[1].set_ylabel(r'$\\sigma_m$')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax[1].set_xticklabels(ticklabels)\n",
    "\n",
    "\n",
    "\n",
    "### pad \n",
    "t3pad_mesh = np.expand_dims(t3pad,axis=0)\n",
    "t3pad_mesh = np.repeat(t3pad_mesh,8,axis=0).T\n",
    "pangles = np.linspace(0,180,8)\n",
    "cmap_min = np.ma.min(electronflux[:,:,4][electronflux[:,:,4]>0])\n",
    "cmap_max = np.min([np.ma.max(electronflux[:,:,4][electronflux[:,:,4]>0]),10**6])\n",
    "\n",
    "pcm3=ax[2].pcolormesh(t3pad_mesh,pangle,(electronflux[:,:,4]),cmap='gist_stern',norm=colors.LogNorm(vmin=cmap_min,vmax=5e5),shading='gouraud')\n",
    "\n",
    "ax[2].set_ylabel(r'electron PAD')\n",
    "ax[2].set_ylim([0,180])\n",
    "ax[2].set_yticks([0,45,90,135,180])\n",
    "\n",
    "\n",
    "ticklocs,ticklabels = tasteful_ticks(t3pad)\n",
    "ax[2].set_xticks(ticklocs)\n",
    "ax[2].set_xticklabels(ticklabels)\n",
    "# ax[2].set_xlim(t3pad[int(len(t3pad)/2)],t3pad[-1])\n",
    "\n",
    "cbar=fig.colorbar(pcm3, ax=ax[2])\n",
    "cbar.set_label('number flux', rotation=90)\n",
    "\n",
    "pangle_centroid = np.repeat(np.expand_dims(pangles,1),t3pad.shape[0],1).T\n",
    "centroids_epad = np.ma.average(pangle_centroid,weights=electronflux[:,:,4],axis=1)\n",
    "ax[2].plot(t3pad,centroids_epad,color='k',ls='--',lw=5)\n",
    "\n",
    "# for j in hcs_sb[0]:\n",
    "#     ax[2].axvline(t3pad[j],ls='--',c='blue',lw=4)\n",
    "\n",
    "# for i in range(len(hcs_regions)):\n",
    "#     ax[0].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "#     ax[1].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "#     ax[2].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='k',alpha=0.1)\n",
    "\n",
    "# for i in hcs_walls:\n",
    "#     ax[0].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "#     ax[1].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "#     ax[2].axvspan(t3pad[hcs_regions[i][0]],t3pad[hcs_regions[i][-1]],color='g',alpha=0.1)\n",
    "\n",
    "# for i in range(0,n-1):\n",
    "#     var_name = plot_list[i]\n",
    "\n",
    "#     t_name = epoch_choice[var_name]\n",
    "#     var_ass = var_dict[var_name]\n",
    "#     t_ass = var_dict[t_name]\n",
    "\n",
    "#     plot_label = label_dict[var_name]\n",
    "#     lt = np.shape(t_ass)[0]\n",
    "\n",
    "#     if n > 1:\n",
    "#         ax[i+3].plot(t_ass,var_ass,label='{}'.format(plot_label))\n",
    "#         ax[i+3].set_xticks(ticklocs)\n",
    "#         ax[i+3].set_xticklabels(ticklabels)\n",
    "#         ax[i+3].locator_params(axis='x', nbins=6)\n",
    "#         ax[i+3].set_ylabel(r'{}'.format(plot_label))\n",
    "#         ax[i+3].yaxis.set_minor_locator(AutoMinorLocator(n = 5))\n",
    "#         if var_name == 'phi_B':\n",
    "#             ax[i+3].set_ylim([0,360])\n",
    "#             ax[i+3].set_yticks([0,90,180,270,360])\n",
    "#         if var_name == 'Tperpp':\n",
    "#             ax[i+3].plot(t_ass,var_dict['Tparp'],color='orange',label=r'{}'.format(label_dict['Tparp']))\n",
    "#             ax[i+3].set_ylabel(r'$T_p$ (eV)')\n",
    "\n",
    "#         if var_name =='Tparp':\n",
    "#             ax[i+3].plot(t_ass,var_dict['Tperpp'],color='orange',label=r'{}'.format(label_dict['Tperpp']))\n",
    "#     else:\n",
    "#         ax[3].plot(t_ass,var_ass,label='{}'.format(var_name))\n",
    "#         ax[3].set_xticks([t_ass[0],t_ass[int(lt/4)],t_ass[int(lt/2)],t_ass[int(3*lt/4)],t_ass[int(lt)-1]])\n",
    "#         ax[3].locator_params(axis='x', nbins=6)\n",
    "#         ax[3].set_ylabel('{}'.format(plot_label))\n",
    "\n",
    "# ax[-1].legend()\n",
    "# ax[-1].set_xticks(ticklocs)\n",
    "\n",
    "# ax[-1].set_xticklabels(ticklabels)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('wavelet stats 082525, days = {}, zoom.pdf'.format(days),format='pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot wavelet\n",
    "\n",
    "\n",
    "### Plotting time\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "plot_list = ['Bmag','Bx','By','Bz','ni','Vmag','Tperpp']\n",
    "n = len(plot_list)\n",
    "ticklocs,ticklabels = tasteful_ticks(t3pad)\n",
    "\n",
    "fig,ax=plt.subplots(n+3-1,1,figsize=(20,6 + 3 * n),layout='compressed')\n",
    "### Plotting time\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "# plot_list = ['Bmag','phi_B','ni','Vmag']\n",
    "plot_list = []\n",
    "n = len(plot_list)\n",
    "ticklocs,ticklabels = tasteful_ticks(t3pad)\n",
    "\n",
    "# fig,ax=plt.subplots(3,1,figsize=(20,6 + 3 * n),layout='compressed')\n",
    "\n",
    "# wavelet\n",
    "# ax[0].set_xlim(len(tB)/2,len(tB))\n",
    "# pcm1=ax[0].pcolormesh(df.index,freqs,(eb_fluc),norm=colors.LogNorm(vmin=1e-6,vmax=1e1), cmap='jet',rasterized=True)\n",
    "# cbar=fig.colorbar(pcm1, ax=ax[0])\n",
    "# cbar.set_label(r'$E_{\\delta B}$',rotation=90)\n",
    "# ticklocs,ticklabels = tasteful_ticks(tB)\n",
    "# ax[0].set_ylabel(r'$E_{\\delta B}$')\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[0].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "# ax[0].set_xticklabels(ticklabels)\n",
    "\n",
    "# # sigm\n",
    "# # ax[1].set_xlim(len(tB)/2,len(tB))\n",
    "# pcm2=ax[1].pcolormesh(df.index,freqs,(sigm),vmin=-1,vmax=1, cmap='jet',rasterized=True)\n",
    "# cbar=fig.colorbar(pcm2, ax=ax[1])\n",
    "# cbar.set_label(r'$\\sigma_m$', rotation=90)\n",
    "# ax[1].set_ylabel(r'$\\sigma_m$')\n",
    "# ax[1].set_yscale('log')\n",
    "# ax[1].xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "# ax[1].set_xticklabels(ticklabels)\n",
    "\n",
    "\n",
    "\n",
    "# ### pad \n",
    "# t3pad_mesh = np.expand_dims(t3pad,axis=0)\n",
    "# t3pad_mesh = np.repeat(t3pad_mesh,8,axis=0).T\n",
    "# pangles = np.linspace(0,180,8)\n",
    "# cmap_min = np.ma.min(electronflux[:,:,4][electronflux[:,:,4]>0])\n",
    "# cmap_max = np.min([np.ma.max(electronflux[:,:,4][electronflux[:,:,4]>0]),10**6])\n",
    "\n",
    "# pcm3=ax[2].pcolormesh(t3pad_mesh,pangle,(electronflux[:,:,4]),cmap='gist_stern',norm=colors.LogNorm(vmin=cmap_min,vmax=5e5),shading='gouraud')\n",
    "\n",
    "# ax[2].set_ylabel(r'electron PAD')\n",
    "# ax[2].set_ylim([0,180])\n",
    "# ax[2].set_yticks([0,45,90,135,180])\n",
    "\n",
    "\n",
    "# ticklocs,ticklabels = tasteful_ticks(t3pad)\n",
    "# ax[2].set_xticks(ticklocs)\n",
    "# ax[2].set_xticklabels(ticklabels)\n",
    "# # ax[2].set_xlim(t3pad[int(len(t3pad)/2)],t3pad[-1])\n",
    "\n",
    "# cbar=fig.colorbar(pcm3, ax=ax[2])\n",
    "# cbar.set_label('number flux', rotation=90)\n",
    "\n",
    "# pangle_centroid = np.repeat(np.expand_dims(pangles,1),t3pad.shape[0],1).T\n",
    "# centroids_epad = np.ma.average(pangle_centroid,weights=electronflux[:,:,4],axis=1)\n",
    "# ax[2].plot(t3pad,centroids_epad,color='k',ls='--',lw=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pad\n",
    "\n",
    "# t3pad_mesh = np.expand_dims(t3pad,axis=0)\n",
    "# t3pad_mesh = np.repeat(t3pad_mesh,8,axis=0).T\n",
    "# pangles = np.linspace(0,180,8)\n",
    "# cmap_min = np.ma.min(electronflux[:,:,4][electronflux[:,:,4]>0])\n",
    "# cmap_max = np.min([np.ma.max(electronflux[:,:,4][electronflux[:,:,4]>0]),10**6])\n",
    "\n",
    "# pcm3=ax[2].pcolormesh(t3pad_mesh,pangle,(electronflux[:,:,4]),cmap='gist_stern',norm=colors.LogNorm(vmin=cmap_min,vmax=5e5),shading='gouraud')\n",
    "# ax[2].set_ylabel(r'electron PAD')\n",
    "# # ax[2].set_xticks([0,len(t3pad)/4,len(t3pad)/2,3*len(t3pad)/4,len(t3pad)])\n",
    "# ax[2].set_xticklabels(['' for i in range(ax[2].get_xticks().shape[0])]);\n",
    "# ax[2].set_ylim([0,180])\n",
    "# ax[2].set_yticks([0,45,90,135,180])\n",
    "# ax[2].set_xticks(ticklocs)\n",
    "# ax[2].set_xticklabels(ticklabels)\n",
    "\n",
    "\n",
    "# ax[2].set_xlim([t3pad[int(t3pad.size/2)],t3pad[-1]])\n",
    "\n",
    "\n",
    "cbar=fig.colorbar(pcm3, ax=ax[2])\n",
    "cbar.set_label('number flux', rotation=90)\n",
    "\n",
    "pangle_centroid = np.repeat(np.expand_dims(pangles,1),t3pad.shape[0],1).T\n",
    "centroids_epad = np.ma.average(pangle_centroid,weights=electronflux[:,:,4],axis=1)\n",
    "ax[2].plot(t3pad,centroids_epad,color='k',ls='--',lw=5)\n",
    "for j in hcs_sb[0]:\n",
    "    ax[2].axvline(t3pad[j],ls='--',c='blue',lw=4)\n",
    "\n",
    "for i in range(0,n-1):\n",
    "    var_name = plot_list[i]\n",
    "\n",
    "    t_name = epoch_choice[var_name]\n",
    "    var_ass = var_dict[var_name]\n",
    "    t_ass = var_dict[t_name]\n",
    "\n",
    "    plot_label = label_dict[var_name]\n",
    "    lt = np.shape(t_ass)[0]\n",
    "\n",
    "    if n > 1:\n",
    "\n",
    "\n",
    "        ax[i+3].plot(t_ass,var_ass,label='{}'.format(plot_label))\n",
    "        ax[i+3].set_xticks(ticklocs)\n",
    "        ax[i+3].set_xticklabels(ticklabels)\n",
    "\n",
    "        # ax[i+3].set_xlim([t3pad[int(t3pad.size/2)],t3pad[-1]])\n",
    "\n",
    "        ax[i+3].locator_params(axis='x', nbins=6)\n",
    "        ax[i+3].set_ylabel(r'{}'.format(plot_label))\n",
    "\n",
    "        ax[i+3].yaxis.set_minor_locator(AutoMinorLocator(n = 5))\n",
    "        if var_name == 'ni':\n",
    "            ax[i+3].set_ylim([0,20])\n",
    "        if var_name == 'phi_B':\n",
    "            ax[i+3].set_ylim([0,360])\n",
    "            ax[i+3].set_yticks([0,90,180,270,360])\n",
    "        if var_name == 'Tperpp':\n",
    "            ax[i+3].plot(t_ass,var_dict['Tparp'],color='orange',label=r'{}'.format(label_dict['Tparp']))\n",
    "            ax[i+3].set_ylabel(r'$T_p$ (eV)')   \n",
    "\n",
    "        if var_name =='Tparp':\n",
    "            ax[i+3].plot(t_ass,var_dict['Tperpp'],color='orange',label=r'{}'.format(label_dict['Tperpp']))\n",
    "    else:\n",
    "        ax[3].plot(t_ass,var_ass,label='{}'.format(var_name))\n",
    "        ax[3].set_xticks([t_ass[0],t_ass[int(lt/4)],t_ass[int(lt/2)],t_ass[int(3*lt/4)],t_ass[int(lt)-1]])\n",
    "        ax[3].locator_params(axis='x', nbins=6)\n",
    "        ax[3].set_ylabel('{}'.format(plot_label))\n",
    "\n",
    "ax[-1].legend()\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig('wavelet stats {}.pdf'.format(days),format='pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4159bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get wave statistics across interval\n",
    "d_temp = pd.read_csv('/Users/sfordin/Documents/Science-Projects/01-psp-wind-conjunction/conjunction data/mva_params_2024_12_123024.csv')\n",
    "startdate_list = d_temp.values[:,0]\n",
    "start_epochs = np.array([cdf.cdfepoch.compute_epoch([int(date_starts[i][0:4]),int(date_starts[i][5:7]),int(date_starts[i][8:10]),\n",
    "                                            int(date_starts[i][11:13]),int(date_starts[i][14:16]),int(date_starts[i][17:19]),\n",
    "                                            int(date_starts[i][20:])]) for i in range(len(date_starts))])\n",
    "\n",
    "preds_list = d_temp.values[:,-1]        \n",
    "\n",
    "first_epoch = np.argmax(start_epochs > cdf.cdfepoch.compute_epoch(date))[0]\n",
    "last_epoch = np.argmax(start_epochs > cdf.cdfepoch.compute_epoch([date[0],date[1],date[2]+days,date[3],date[4],date[5]]))[0]\n",
    "pred_range = preds_list[first_epoch:last_epoch]\n",
    "\n",
    "print(startdate_list[first_epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute two strahl metrics:\n",
    "# 1. Prominence of parallel versus anti-parallel electrons (represented by ratio of counts in first bin to last bin)\n",
    "# 2. Prominence of strahl versus scattered electrons (represented by ratio of summed counts in first+last bins to all counts)\n",
    "\n",
    "par_bins = [0]\n",
    "antipar_bins = [-1]\n",
    "\n",
    "par_counts = np.sum(electronflux[:,par_bins,4],axis=1)\n",
    "antipar_counts = np.sum(electronflux[:,antipar_bins,4],axis=1)\n",
    "all_counts = np.sum(electronflux[:,1:-1,4],axis=1)\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "ax.plot(par_counts/antipar_counts,c='blue',label=r'$N_\\parallel/N_{\\nparallel}$')\n",
    "ax.plot((par_counts+antipar_counts)/all_counts,c='orange',label=r'$(N_\\parallel+N_{\\nparallel})/N_{halo}$')\n",
    "ax.legend(frameon=False,bbox_to_anchor=(1,1))\n",
    "ax.axhline(1,ls='--',c='k')\n",
    "ax.set_ylim([1e-2,1e2])\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('ratio')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87676d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(var_dict.keys())\n",
    "plot_list = ['Bmag','e05','Tp','Vx']\n",
    "n = len(plot_list)\n",
    "fig,ax=plt.subplots(n,1,figsize=(10,4*n))\n",
    "for i in range(0,n):\n",
    "    var_name = plot_list[i]\n",
    "    t_name = epoch_choice[var_name]\n",
    "    print(n)\n",
    "    if n > 1:\n",
    "        ax[i].plot(var_dict[t_name],var_dict[var_name],label='{}'.format(var_name))\n",
    "        ax[i].set_title('{}'.format(var_name))\n",
    "        ax[i].set_xlabel('{}'.format(var_name))\n",
    "        ax[i].set_xlabel('{}'.format(var_name))\n",
    "        \n",
    "    else:\n",
    "        ax.plot(var_dict[t_name],var_dict[var_name],label='{}'.format(var_name))\n",
    "        ax.set_title('{}'.format(var_name))\n",
    "        ax.set_xlabel('{}'.format(var_name))\n",
    "        ax.set_xlabel('{}'.format(var_name))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08245cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(2,1,figsize=(15,15))\n",
    "# cmap = mpl.colormaps.get_cmap('viridis')\n",
    "# ax.pcolor(t3pad,electronflux[:,4,:].T)\n",
    "# check_eflux = np.nan_to_num(electronflux[:,4,:])\n",
    "# ax[0].imshow(electronflux[:,4,:].T,aspect='auto',origin='lower',vmin=5,vmax=255)\n",
    "\n",
    "# ax[1].imshow(check_eflux.T,norm='log',aspect='auto',origin='lower',vmin=1,vmax=10**2)\n",
    "\n",
    "\n",
    "# ax[0].set_xticks([0,np.shape(electronflux)[0]])\n",
    "# ax[0].set_xticklabels([cdf.cdfepoch.breakdown(t3pad[0])[0:4],cdf.cdfepoch.breakdown(t3pad[-1])[0:4]])\n",
    "# ax[0].set_title('electron PAD')\n",
    "# ax[1].set_xticks([0,np.shape(electronflux)[0]])\n",
    "# ax[1].set_xticklabels([cdf.cdfepoch.breakdown(t3pad[0])[0:4],cdf.cdfepoch.breakdown(t3pad[-1])[0:4]])\n",
    "# ax[1].set_title('electron PAD, no nan')\n",
    "chan = 4\n",
    "wind_flux_val_norm = []\n",
    "for i in range(len(t3pad)):\n",
    "    wind_flux_val_norm.append(electronflux[i,:,chan]/\n",
    "                                            max(electronflux[i,:,chan]))\n",
    "wind_flux_val_norm = np.array(wind_flux_val_norm)\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.pcolor(t3pad, pangle[10,:], wind_flux_val_norm.T)\n",
    "\n",
    "# plt.xticks([t3pad[0],t3pad[-1]],labels=[cdf.cdfepoch.breakdown(t3pad[0])[0:4],cdf.cdfepoch.breakdown(t3pad[-1])[0:4]])\n",
    "# ax[1].set_title('electron PAD, no nan')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jaye's conjunction jambalaya\n",
    "\n",
    "conjumble = [['2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', '2020-02-01', '2020-02-02'], #E4\n",
    "['2020-06-06','2020-06-07','2020-06-08','2020-06-09','2020-06-10'], #E5\n",
    "['2020-09-25','2020-09-30'], #E6\n",
    "['2021-01-17','2021-01-19','2021-01-20'], #E7\n",
    "['2021-04-28','2021-04-29'], #E8gr8\n",
    "['2021-08-08','2021-08-09','2021-08-10','2021-08-11'], #E9\n",
    "['2021-11-22'], #E10\n",
    "['2022-02-25'], #E11\n",
    "['2022-06-02', '2022-06-03'], #E12\n",
    "['2022-09-04','2022-09-05','2022-09-06'], #E13\n",
    "['2022-12-12'], #E14\n",
    "['2023-03-14', '2023-03-15', '2023-03-16', '2023-03-17', '2023-03-18'], #E15\n",
    "['2023-06-21','2023-06-22'], #E16\n",
    "['2023-09-26', '2023-09-27', '2023-09-28'], #E17\n",
    "['2023-12-29'], #E18\n",
    "['2024-03-29', '2024-03-30'], #E19\n",
    "['2024-06-24','2024-06-25','2024-06-28','2024-06-29','2024-6-30','2024-07-01','2024-07-02','2024-07-03','2024-07-04'], #E20\n",
    "['2024-09-26','2024-09-28','2024-09-29','2024-09-30','2024-10-01','2024-10-02','2024-10-04'], #E21\n",
    "['2024-12-23','2024-12-24','2024-12-25'], #E22\n",
    "['2025-03,19','2025-03-21','2025-03-22','2025-03-23','2025-03-27','2025-03-28'] #E23\n",
    "]\n",
    "\n",
    "## 1. Get set of days associated with each encounter\n",
    "for enc in conjumble:\n",
    "    for i in range(len(enc)):\n",
    "        date = enc[i]\n",
    "        y = int(date[0:4])\n",
    "        m = int(date[5:7])\n",
    "        d = int(date[8:10])\n",
    "\n",
    "        y_str = date[0:4]\n",
    "        m_str = date[5:7]\n",
    "        d_str = date[8:10]\n",
    "\n",
    "        y_f = y\n",
    "        m_f = m\n",
    "        d_f = d + 1\n",
    "\n",
    "        yf_str = str(y_f)\n",
    "        if m_f > 9:\n",
    "            mf_str = str(m_f)\n",
    "        else:\n",
    "            mf_str = '0{}'.format(m_f)\n",
    "            \n",
    "        if d_f > 9:\n",
    "            df_str = str(d_f)\n",
    "        else:\n",
    "            df_str = '0{}'.format(d_f)\n",
    "\n",
    "        # If next day is out of bounds, change days\n",
    "        if m in [4,6,9,11]:\n",
    "            if d == 30:\n",
    "                m_f += 1\n",
    "                d_f = 1\n",
    "                yf_str = str(y_f)\n",
    "                if m_f > 9:\n",
    "                    mf_str = str(m_f)\n",
    "                else:\n",
    "                    mf_str = '0{}'.format(m_f)\n",
    "                df_str = '01'\n",
    "\n",
    "        elif m in [1,2,3,5,7,8,10]:\n",
    "            if d == 31:\n",
    "                m_f += 1\n",
    "                d_f = 1\n",
    "                yf_str = str(y_f)\n",
    "                if m_f > 9:\n",
    "                    mf_str = str(m_f)\n",
    "                else:\n",
    "                    mf_str = '0{}'.format(m_f)\n",
    "                df_str = '01'\n",
    "\n",
    "        elif m == 12:\n",
    "            if d == 31:\n",
    "                y_f += 1\n",
    "                m_f = 1\n",
    "                d_f = 1\n",
    "                yf_str = str(y_f)\n",
    "                mf_str = '01'\n",
    "                df_str = '01'\n",
    "        \n",
    "\n",
    "        trange = [y_str + '-' + m_str + '-' + d_str + '/00:00:00.000',yf_str +'-' + mf_str + '-' + df_str + '/00:00:00.000']\n",
    "        plotbot.ploptions.display_figure = True\n",
    "        # plotbot.ploptions.display_figure = False\n",
    "        \n",
    "        plotbot.plotbot(trange,plotbot.mag_rtn_4sa.bmag,1,plotbot.mag_rtn_4sa.br,1,plotbot.epad.strahl,2)\n",
    "\n",
    "        tpad = np.array(plotbot.epad.datetime_array)\n",
    "        tB = np.array(plotbot.mag_rtn_4sa.datetime_array)\n",
    "        epad = 10**np.array(plotbot.epad.strahl.data)\n",
    "        pangles = np.array(plotbot.epad.pitch_angle_y_values.data)\n",
    "        Br = np.array(plotbot.mag_rtn_4sa.br.data)\n",
    "        Bn = np.array(plotbot.mag_rtn_4sa.bn.data)\n",
    "        phi_B = np.degrees(np.arctan2(Br,Bn)) + 180\n",
    "        \n",
    "        ### PLOTBOT IS APPENDING DATA INSTEAD OF REPLACING--WHY?\n",
    "\n",
    "        ticklocs,ticklabels = tasteful_ticks(tB)\n",
    "\n",
    "        fig,ax=plt.subplots(1,1,figsize=(10,4))\n",
    "        ax.scatter(tB,phi_B,s=3)\n",
    "        ax.set_ylabel(r'$\\phi_B \\ (\\circ) \\n$ ')\n",
    "        ax.set_xticks(ticklocs)\n",
    "        ax.set_xticklabels(ticklabels)\n",
    "        \n",
    "## 2. Input tpad, tB, epad, phi_B into hcs_loc\n",
    "        hcs_sb,hcs_bounds = hcs_loc(tpad,tB,epad,phi_B,parapar_rats = [1/3,3],beam_bg_rats = [2/3,3/2],return_bounds=True,med_filter_len=49)\n",
    "        hcs_walls = strahl_walls(epad,pangles,region_inds=hcs_bounds)\n",
    "        for k in hcs_sb[0]:\n",
    "            ax.axvline(tpad[k],ls='--',c='k')\n",
    "        for j in hcs_walls:\n",
    "            ax.axvspan(tpad[hcs_bounds[j][0]],tpad[hcs_bounds[j][-1]],color='g',alpha=0.1)\n",
    "        plt.savefig('/Users/sfordin/Documents/Science-Projects/01-psp-wind-conjunction/figures/jaye conjumble/fig phi crossings {}.pdf'.format(date),format='pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a371a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
