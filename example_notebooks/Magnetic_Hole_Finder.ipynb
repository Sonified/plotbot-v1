{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71e03e3-e18b-4923-8fb3-25ce3961abfd",
   "metadata": {},
   "source": [
    "# PSP Automated Magnetic Hole Finder\n",
    "## By: Robert Alexander + Jaye Verniero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6e5ed-dfa5-40f5-9949-079fff99d430",
   "metadata": {},
   "source": [
    "### 0.1) Import Packages, Define Helper Functions, and Set Save Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2739723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Initial Configuration\n",
    "\n",
    "# --- Plotbot Core Imports ---\n",
    "try:\n",
    "    from plotbot import print_manager as pm\n",
    "    # Configure Print Manager Verbosity (adjust as needed for debugging)\n",
    "    pm.show_error = True\n",
    "    pm.show_warnings = True\n",
    "    pm.show_status = True     # Good for seeing high-level progress\n",
    "    pm.show_debug = False     # Set to True for very detailed internal Plotbot logs\n",
    "    pm.show_datacubby = False # Set to True to debug DataCubby interactions\n",
    "    pm.show_processing = False# Set to True for Plotbot data processing steps\n",
    "    print(\"\u2705 Successfully imported and configured Plotbot's print_manager.\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0\ufe0f Could not import Plotbot's print_manager. Some log messages may be missing.\")\n",
    "    pm = None\n",
    "\n",
    "# Import for direct data loading/populating DataCubby & the specific global instances\n",
    "from plotbot import get_data as plotbot_get_data \n",
    "from plotbot import mag_rtn  # For MAG_RTN data (1 sample/cycle)\n",
    "from plotbot import config\n",
    "# from plotbot import mag_rtn_4sa # If you also need 4sa MAG data in snapshots\n",
    "# from plotbot import proton      # Example: if you want proton data\n",
    "# from plotbot import epad        # Example: if you want electron PAD data\n",
    "\n",
    "# Import for snapshotting\n",
    "from plotbot.data_snapshot import save_data_snapshot, load_data_snapshot\n",
    "\n",
    "# --- Local Application Imports ---\n",
    "# For running your analysis algorithm\n",
    "from magnetic_hole_finder.magnetic_hole_finder_core import HoleFinderSettings, detect_magnetic_holes_and_generate_outputs\n",
    "\n",
    "# --- Standard Library Imports ---\n",
    "import os\n",
    "import json # For settings files, though core function handles its own now\n",
    "from datetime import datetime\n",
    "from collections import Counter # For handling the returned counter from analysis\n",
    "\n",
    "# --- Third-Party Data Science Libraries (primarily for ad-hoc notebook use if needed) ---\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt # If doing custom plots in the notebook\n",
    "\n",
    "# --- Warnings Handling ---\n",
    "from warnings import simplefilter\n",
    "import warnings\n",
    "simplefilter(action='ignore', category=DeprecationWarning) # Ignore general deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\") # Example specific warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in scalar divide\") # Example\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"IPython.core.pylabtools\") # For IPython\n",
    "\n",
    "# --- Final Import Confirmation ---\n",
    "current_time_consolidated = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'{current_time_consolidated} - \ud83d\udcda All libraries imported and environment configured.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed618fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- \ud83d\udcbd CONFIGURE THE DEFAULT DATA DIRECTORY \ud83d\udcbd -------//\n",
    "# This must be set before pyspedas is imported/run, as pyspedas caches configuration at import time.\n",
    "\n",
    "config.data_dir = '../data'  # Go up one level to Plotbot/data/\n",
    "\n",
    "import os\n",
    "print(f\"\ud83d\udcc1 Data directory absolute path: {os.path.abspath(config.data_dir)}\")\n",
    "\n",
    "# ------- \ud83d\udce1 CONFIGURE THE DEFAULT DATA SERVER \ud83d\udce1 -------//\n",
    "\n",
    "# config.data_server = 'spdf'\n",
    "config.data_server = 'berkeley'\n",
    "# config.data_server = 'dynamic' #Will attempt to download from spdf first and then try berkeley\n",
    "\n",
    "# ------- \ud83d\udda8\ufe0f CONFIGURE PRINT MANAGER \ud83d\udda8\ufe0f -------//\n",
    "pm.show_status = True\n",
    "# pm.show_debug = True      # Optional: uncomment for maximum detail\n",
    "# pm.show_processing = True # Optional: uncomment for processing steps\n",
    "# pm.show_datacubby = True  # Optional: uncomment for data caching steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72f6494",
   "metadata": {},
   "source": [
    "### Load The Snapshot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data_snapshot('Magnetic_Hole_Multi_Encounter_Snapshot.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7225fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"SPEDAS_DATA_DIR: {os.environ.get('SPEDAS_DATA_DIR', 'NOT_SET')}\")\n",
    "print(f\"config.data_dir: {config.data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2285303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Common Setup ---\n",
    "# Ensure necessary data modules are imported\n",
    "from plotbot import epad, mag_rtn_4sa, proton, showda_holes\n",
    "\n",
    "trange_E9 = ['2021-08-10 00:00:00', '2021-08-10 02:00:00']\n",
    "trange_E10 = ['2021-11-22 00:30:00', '2021-11-22 03:30:00']\n",
    "trange_E11 = ['2022-02-25 12:00:00', '2022-02-25 13:00:00']\n",
    "trange_E15_1 = ['2023-03-16 02:15:00', '2023-03-16 02:30:00']\n",
    "trange_E15_2 = ['2023-03-17 20:30:00', '2023-03-17 21:45:00']\n",
    "trange_E15_2_tight = ['2023-03-17 21:05:00', '2023-03-17 21:15:00']\n",
    "trange_E17 = ['2023-09-28 06:32:00', '2023-09-28 06:45:00']\n",
    "trange_E17_w = ['2023-09-28 06:00:00', '2023-09-28 07:30:00']\n",
    "\n",
    "# trange = trange_E15_2_tight\n",
    "# Or any other trange you want to test\n",
    "# --- Select active time range ---\n",
    "# trange = trange_E9\n",
    "# trange = trange_E10\n",
    "# trange = trange_E11\n",
    "# trange = trange_E15_1\n",
    "# trange = trange_E15_2\n",
    "# trange = trange_E17\n",
    "trange = trange_E17\n",
    "\n",
    "\n",
    "mh_marker_file_path = \"/Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E17/E17_PSP_FIELDS_2023-09-28_053200_to_074500_Bmag_Holes/PSP_MH_Marker_Set_E17_2023-09-28_053200_to_074500_V3_MAX_AND_MIN.txt\"\n",
    "# mh_marker_file_path = \"/Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E15/E15_PSP_FIELDS_2023-03-17_203000_to_214500_Bmag_Holes/PSP_MH_Marker_Set_E15_2023-03-17_203000_to_214500_V3_MAX_AND_MIN.txt\"\n",
    "\n",
    "\n",
    "# Optional: Turn on debug prints if needed\n",
    "# pm.show_debug = True\n",
    "\n",
    "# --- Define the panel definitions (REQUIRED for multi-panel mode) ---\n",
    "# *** Panel Order Updated ***\n",
    "panel_defs = [\n",
    "    # --- Panel 1: Upper Left (|B| vs EPAD Centroids) --- <<< MOVED HERE\n",
    "    {'x_data': mag_rtn_4sa.bmag, 'y_data': epad.centroids, 'marker_file': mh_marker_file_path, 'title': '|B| vs EPAD Centroids'}, \n",
    "    # --- Panel 2: Upper Right (|B| vs Anisotropy) --- <<< Was Panel 1\n",
    "    {'x_data': mag_rtn_4sa.bmag, 'y_data': proton.anisotropy, 'marker_file': mh_marker_file_path, 'title': '|B| vs Proton Anisotropy'}, \n",
    "    # --- Panel 3: Lower Left (|B| vs Proton T Parallel) ---\n",
    "    {'x_data': mag_rtn_4sa.bmag, 'y_data': proton.t_par, 'marker_file': mh_marker_file_path, 'title': '|B| vs Proton T Parallel'},\n",
    "    # --- Panel 4: Lower Right (|B| vs Proton T Perpendicular) ---\n",
    "    {'x_data': mag_rtn_4sa.bmag, 'y_data': proton.t_perp, 'marker_file': mh_marker_file_path, 'title': '|B| vs Proton T Perpendicular'} \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "proton.energy_flux\n",
    "proton.phi_flux\n",
    "\n",
    "# --- Call showda_holes using panel_definitions ---\n",
    "fig, axes = showda_holes(\n",
    "    # --- Required Arguments for Multi-Panel ---\n",
    "    trange,                   # Your time range list\n",
    "    panel_definitions=panel_defs, # The list of panel definitions from above\n",
    "\n",
    "    # --- Optional Global Keyword Arguments (Defaults shown) ---\n",
    "    # main_title=None,             # Default: Auto-generates \"Encounter: Start to End\". Provide string to override.\n",
    "    main_title_fontsize=18,    # Default: base_fontsize + 4. Provide integer to override.\n",
    "    main_title_y=0.98,           # Default: 0.98 (near top). Use e.g., 0.95 to move down.\n",
    "    # --- Other KWARGS passed to _plot_single_hodogram_panel as defaults ---\n",
    "    # figsize=(14, 10),            # Default adjusts based on panel number. Example: (14, 10)\n",
    "    base_fontsize=14             # Default: 12. Example: 10\n",
    "    # x_label=None,                # Default X label if not set in panel_def (tries data object)\n",
    "    # y_label=None,                # Default Y label if not set in panel_def (tries data object)\n",
    "    # inside_color='red',          # Default color for points inside holes\n",
    "    # outside_color='blue',        # Default color for points outside holes\n",
    "    # inside_size=50,              # Default marker size for points inside holes\n",
    "    # outside_size=10,             # Default marker size for points outside holes\n",
    "    # alpha=0.7,                   # Default marker transparency (0.0 to 1.0)\n",
    ")\n",
    "\n",
    "# --- Check and Use Result ---\n",
    "if fig and axes is not None:\n",
    "    print(f\"Multi-panel plot generated. axes shape: {axes.shape}\")\n",
    "    # You can access individual axes, e.g., axes[0, 1] for the top-right panel\n",
    "else:\n",
    "    print(\"Multi-panel showda_holes failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c19226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Ensure os is imported\n",
    "\n",
    "# Define the main directory where all outputs will go\n",
    "# This is what the user might change.\n",
    "BASE_SAVE_DIRECTORY = os.path.abspath(\"MH_Scan_Output\") # Path relative to project root\n",
    "os.makedirs(BASE_SAVE_DIRECTORY, exist_ok=True) # Create it if it doesn't exist\n",
    "print(f'\ud83d\udedf Algorithm output base directory set to: {BASE_SAVE_DIRECTORY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configure HoleFinderSettings for the Run\n",
    "\n",
    "# Instantiate settings with defaults from the class\n",
    "mh_run_settings = HoleFinderSettings()\n",
    "\n",
    "# === Customize parameters for THIS SPECIFIC RUN ===\n",
    "# Values shown here are examples if you want to override the defaults \n",
    "# defined in the HoleFinderSettings class. If the default is fine, you don't need to set it here.\n",
    "\n",
    "# --- Core Algorithm Parameters ---\n",
    "mh_run_settings.INSTRUMENT_SAMPLING_RATE = 292.9 \n",
    "mh_run_settings.use_calculated_sampling_rate = True\n",
    "mh_run_settings.depth_percentage_threshold = 0.25\n",
    "mh_run_settings.smoothing_window_seconds = 8.0\n",
    "mh_run_settings.derivative_window_seconds = 0.2\n",
    "mh_run_settings.min_max_finding_smooth_window = 0.3\n",
    "mh_run_settings.mean_threshold = 0.8\n",
    "mh_run_settings.search_in_progress_output = True  # For verbose logging during detection\n",
    "mh_run_settings.additional_seconds_for_min_search = 0.2\n",
    "mh_run_settings.asymetric_peak_threshold = 0.25\n",
    "mh_run_settings.symmetrical_peak_scan_window_in_secs = 2.0\n",
    "mh_run_settings.Bave_scan_seconds = 0.1\n",
    "mh_run_settings.Bave_window_seconds = 20.0\n",
    "mh_run_settings.wide_angle_threshold = 15.0\n",
    "mh_run_settings.small_threshold_cross_flag_samples = 10\n",
    "mh_run_settings.small_threshold_cross_adjustment_samples = 10\n",
    "\n",
    "# --- Algorithm Breaking Condition Flags ---\n",
    "mh_run_settings.break_for_shallow_hole = True\n",
    "mh_run_settings.break_for_assymettry = False \n",
    "mh_run_settings.break_for_wide_angle = False \n",
    "mh_run_settings.break_for_small_threshold_cross = False\n",
    "mh_run_settings.break_for_complex_hole = False \n",
    "mh_run_settings.threshold_for_derivative_0_crossings_flag = 1000\n",
    "mh_run_settings.break_for_derivative_crossings = False\n",
    "\n",
    "# --- Output Generation Control Flags (for outputs handled by the core .py function) ---\n",
    "mh_run_settings.OUTPUT_MAIN_PLOT = True \n",
    "mh_run_settings.SAVE_MAIN_PLOT = True   \n",
    "mh_run_settings.PLOT_HOLE_MINIMUM_ON_MAIN_PLOT = True \n",
    "mh_run_settings.PLOT_THRESH_CROSS_ON_MAIN_PLOT = True \n",
    "\n",
    "mh_run_settings.OUTPUT_ZERO_CROSSING_PLOT = False # For the specific plot in zero_crossing_analysis\n",
    "\n",
    "mh_run_settings.IZOTOPE_MARKER_FILE_OUTPUT_MAX_AND_MIN = True \n",
    "mh_run_settings.IZOTOPE_MARKER_FILE_OUTPUT_GENERAL = False\n",
    "mh_run_settings.MARKER_FILE_VERSION = 3\n",
    "mh_run_settings.MARKER_FILES_WITH_ANNOTATED_MARKERS = False\n",
    "mh_run_settings.MARKER_FILES_WITH_HOLE_NUMBERS = False\n",
    "\n",
    "mh_run_settings.EXPORT_AUDIO_FILES = True\n",
    "mh_run_settings.AUDIO_SAMPLING_RATE = 22000\n",
    "\n",
    "mh_run_settings.download_only = False # Set to True to only download\n",
    "\n",
    "print(\"HoleFinderSettings configured for this run. Current settings:\")\n",
    "# Pretty print the settings for verification\n",
    "# import json\n",
    "# print(json.dumps(mh_run_settings.__dict__, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trange_E9 = ['2021-08-10 00:00:00', '2021-08-10 02:00:00']\n",
    "trange_E10 = ['2021-11-22 00:30:00', '2021-11-22 03:30:00']\n",
    "trange_E11 = ['2022-02-25 12:00:00', '2022-02-25 13:00:00']\n",
    "trange_E15_1 = ['2023-03-16 02:15:00', '2023-03-16 02:30:00']\n",
    "trange_E15_2 = ['2023-03-17 20:30:00', '2023-03-17 21:45:00']\n",
    "trange_E15_2_tight = ['2023-03-17 21:05:00', '2023-03-17 21:15:00']\n",
    "trange_E17 = ['2023-09-28 06:32:00', '2023-09-28 06:45:00']\n",
    "trange_E17_w = ['2023-09-28 06:00:00', '2023-09-28 07:30:00']\n",
    "\n",
    "\n",
    "\n",
    "trange_E15_2_tighter = ['2023-03-17 21:10:0', '2023-03-17 21:11:00']\n",
    "# trange_E15_2_explore = ['2023-03-17 21:10:15', '2023-03-17 21:10:20']\n",
    "\n",
    "TIME_RANGE_TO_ANALYZE = trange_E15_2_tighter\n",
    "# Or any other trange you want to test\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Starting analysis for trange: {TIME_RANGE_TO_ANALYZE}...\")\n",
    "print(f\"Outputs will be saved within base directory: {BASE_SAVE_DIRECTORY}\")\n",
    "\n",
    "# The main call to the refactored orchestrator function\n",
    "# It now handles sub_save_dir creation, detection, and all standard outputs internally.\n",
    "analysis_results = detect_magnetic_holes_and_generate_outputs(\n",
    "    TIME_RANGE_TO_ANALYZE,\n",
    "    BASE_SAVE_DIRECTORY, # Pass the top-level save directory\n",
    "    mh_run_settings      # Pass the configured settings object\n",
    ")\n",
    "\n",
    "# The function returns the primary scientific results for optional inspection\n",
    "if analysis_results:\n",
    "    magnetic_holes, hole_minima, hole_maxima_pairs, times_clipped, bmag, magnetic_hole_details, returned_hole_counter = analysis_results\n",
    "    print(f\"\\n\u2705 Analysis complete. {returned_hole_counter.get('confirmed', 0)} holes confirmed.\")\n",
    "    # You can still do a quick print of the counter here\n",
    "    print(\"\\n--- Magnetic Hole Detection Summary (from returned counter) ---\")\n",
    "    for key, value in returned_hole_counter.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(f\"All outputs (plots, markers, settings JSON) saved in the run-specific subdirectory.\")\n",
    "else:\n",
    "    print(\"Analysis aborted or returned no results (check logs for errors).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotbot import showda_holes\n",
    "from plotbot import mag_rtn_4sa, proton # Or other data modules you need\n",
    "\n",
    "# Define your time range\n",
    "trange_E9 = ['2021-08-10 00:00:00', '2021-08-10 02:00:00']\n",
    "trange_E10 = ['2021-11-22 00:30:00', '2021-11-22 03:30:00']\n",
    "trange_E11 = ['2022-02-25 12:00:00', '2022-02-25 13:00:00']\n",
    "trange_E15_1 = ['2023-03-16 02:15:00', '2023-03-16 02:30:00']\n",
    "trange_E15_2 = ['2023-03-17 20:30:00', '2023-03-17 21:45:00']\n",
    "trange_E17 = ['2023-09-28 06:32:00', '2023-09-28 06:45:00']\n",
    "trange_E17_w = ['2023-09-28 05:32:00', '2023-09-28 07:45:00']\n",
    "\n",
    "# trange = trange_E9\n",
    "# trange = trange_E10\n",
    "# trange = trange_E11\n",
    "# trange = trange_E15_1\n",
    "# trange = trange_E15_2\n",
    "# trange = trange_E17\n",
    "trange = trange_E17_w\n",
    "\n",
    "#proton temp anisotropy, proton pressure, etc\n",
    "\n",
    "mh_marker_file_path = \"/Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E17/E17_PSP_FIELDS_2023-09-28_053200_to_074500_Bmag_Holes/PSP_MH_Marker_Set_E17_2023-09-28_053200_to_074500_V3_MAX_AND_MIN.txt\" \n",
    "\n",
    "pm.show_debug = False\n",
    "\n",
    "# Call showdahodo with the time range and two variable objects\n",
    "fig, ax = showda_holes(\n",
    "    # --- Required Arguments ---\n",
    "    trange,                    # Your defined time range list\n",
    "    mag_rtn_4sa.br,            # Your X-axis data request\n",
    "    # proton.anisotropy,         # Your Y-axis data request\n",
    "    # proton.beta_pperp,         # Your Y-axis data request\n",
    "    proton.anisotropy,         # Your Y-axis data request\n",
    "    mh_marker_file_path,       # Your marker file path\n",
    "\n",
    "    # --- Optional Keyword Arguments (Defaults shown) ---\n",
    "    # title=\"Hodogram with Magnetic Holes\", # Uncomment and change title string if desired\n",
    "    # x_label=None,                # Leave as None to use data label, or provide string e.g., \"Br (nT)\"\n",
    "    # y_label=None,                # Leave as None to use data label, or provide string e.g., \"Proton Anisotropy\"\n",
    "    # inside_color='red',        # Color for points inside holes\n",
    "    # outside_color='blue',      # Color for points outside holes\n",
    "    inside_size=30,            # Marker size for points inside holes\n",
    "    outside_size=30,           # Marker size for points outside holes\n",
    "    # alpha=0.7,                 # Marker transparency (0.0 to 1.0)\n",
    "    # figsize=(10, 8),           # Figure size (width, height) in inches\n",
    "    base_fontsize=18           # Base font size for text elements\n",
    ")\n",
    "\n",
    "\n",
    "# Example using mag_rtn_4sa data components:\n",
    "# fig, ax = showdahodo(trange, mag_rtn_4sa.br, mag_rtn_4sa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotbot import showdahodo\n",
    "from plotbot import mag_rtn_4sa, proton # Or other data modules you need\n",
    "\n",
    "# Define your time range\n",
    "trange_E9 = ['2021-08-10 00:00:00', '2021-08-10 02:00:00']\n",
    "trange_E10 = ['2021-11-22 00:30:00', '2021-11-22 03:30:00']\n",
    "trange_E11 = ['2022-02-25 12:00:00', '2022-02-25 13:00:00']\n",
    "trange_E15_1 = ['2023-03-16 02:15:00', '2023-03-16 02:30:00']\n",
    "trange_E15_2 = ['2023-03-17 20:30:00', '2023-03-17 21:45:00']\n",
    "trange_E17 = ['2023-09-28 06:32:00', '2023-09-28 06:45:00']\n",
    "trange_E17_w = ['2023-09-28 05:32:00', '2023-09-28 07:45:00']\n",
    "\n",
    "trange = trange_E17_w\n",
    "\n",
    "#proton temp anisotropy, proton pressure, etc\n",
    "\n",
    "# Call showdahodo with the time range and two variable objects\n",
    "fig, ax = showdahodo(trange, mag_rtn_4sa.br, proton.anisotropy )\n",
    "\n",
    "# Example using mag_rtn_4sa data components:\n",
    "# fig, ax = showdahodo(trange, mag_rtn_4sa.br, mag_rtn_4sa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2c46e",
   "metadata": {},
   "source": [
    "### DATA LENGTH CHECKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e08e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "# import numpy as np # For checking array properties\n",
    "# import pandas as pd # For datetime/timestamp checks\n",
    "\n",
    "# # Make sure Plotbot's custom classes are importable\n",
    "# # This might require sys.path adjustments if your notebook isn't in the root\n",
    "# # import sys\n",
    "# # sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Example if notebook is in a subdir\n",
    "\n",
    "# from plotbot.data_classes.psp_mag_classes import mag_rtn_4sa_class # Adjust import as needed\n",
    "# from plotbot.plot_manager import plot_manager # if plot_manager objects are part of the class\n",
    "# from plotbot.ploptions import ploptions # if ploptions objects are part of the class\n",
    "\n",
    "\n",
    "# filepath = \"data_snapshots/full_mission_mag_rtn_4sa.pkl\"\n",
    "# loaded_data = None\n",
    "\n",
    "# try:\n",
    "#     with open(filepath, 'rb') as f:\n",
    "#         loaded_data = pickle.load(f)\n",
    "#     print(f\"Successfully loaded: {filepath}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading snapshot: {e}\")\n",
    "\n",
    "# if loaded_data:\n",
    "#     print(f\"Type of loaded data: {type(loaded_data)}\")\n",
    "#     if isinstance(loaded_data, dict):\n",
    "#         print(f\"Keys in snapshot: {list(loaded_data.keys())}\")\n",
    "#         for key, obj_instance in loaded_data.items():\n",
    "#             print(f\"--- Inspecting: {key} (Type: {type(obj_instance)}) ---\")\n",
    "#             if hasattr(obj_instance, 'datetime_array') and obj_instance.datetime_array is not None:\n",
    "#                 print(f\"  datetime_array len: {len(obj_instance.datetime_array)}\")\n",
    "#                 if len(obj_instance.datetime_array) > 0:\n",
    "#                     print(f\"  datetime_array first element type: {type(obj_instance.datetime_array[0])}\")\n",
    "#             else:\n",
    "#                 print(f\"  datetime_array: Not found or None\")\n",
    "\n",
    "#             if hasattr(obj_instance, 'time') and obj_instance.time is not None:\n",
    "#                 # Check if it's a numpy array to get shape, otherwise len\n",
    "#                 if isinstance(obj_instance.time, np.ndarray):\n",
    "#                     print(f\"  time (TT2000) shape: {obj_instance.time.shape}, size: {obj_instance.time.size}\")\n",
    "#                     if obj_instance.time.size > 0:\n",
    "#                          print(f\"  time first element type: {type(obj_instance.time[0]) if obj_instance.time.ndim > 0 else type(obj_instance.time.item())}\")\n",
    "\n",
    "#                 elif hasattr(obj_instance.time, '__len__'):\n",
    "#                     print(f\"  time (TT2000) len: {len(obj_instance.time)}\")\n",
    "#                     if len(obj_instance.time) > 0:\n",
    "#                          print(f\"  time first element type: {type(obj_instance.time[0])}\")\n",
    "#                 else: # Scalar or other\n",
    "#                     print(f\"  time (TT2000): {obj_instance.time} (Type: {type(obj_instance.time)})\")\n",
    "#             else:\n",
    "#                 print(f\"  time (TT2000): Not found or None\")\n",
    "\n",
    "#             if hasattr(obj_instance, 'field') and obj_instance.field is not None:\n",
    "#                  if isinstance(obj_instance.field, np.ndarray):\n",
    "#                     print(f\"  field shape: {obj_instance.field.shape}\")\n",
    "#                  elif hasattr(obj_instance.field, '__len__'): # e.g. list of arrays\n",
    "#                     print(f\"  field (list) len: {len(obj_instance.field)}\")\n",
    "#                     if len(obj_instance.field) > 0 and hasattr(obj_instance.field[0], 'shape'):\n",
    "#                         print(f\"  field component 0 shape: {obj_instance.field[0].shape}\")\n",
    "\n",
    "#             else:\n",
    "#                 print(f\"  field: Not found or None\")\n",
    "\n",
    "#             if hasattr(obj_instance, 'raw_data') and isinstance(obj_instance.raw_data, dict):\n",
    "#                 print(f\"  raw_data keys: {list(obj_instance.raw_data.keys())}\")\n",
    "#                 for r_key, r_val in obj_instance.raw_data.items():\n",
    "#                     if isinstance(r_val, np.ndarray):\n",
    "#                         print(f\"    raw_data['{r_key}'] shape: {r_val.shape}\")\n",
    "#                     elif isinstance(r_val, list) and r_val and hasattr(r_val[0], 'shape'):\n",
    "#                          print(f\"    raw_data['{r_key}'] (list) len: {len(r_val)}, component 0 shape: {r_val[0].shape}\")\n",
    "#                     elif hasattr(r_val, '__len__'):\n",
    "#                         print(f\"    raw_data['{r_key}'] len: {len(r_val)}\")\n",
    "\n",
    "#     # You might need to adjust the key if mag_rtn_4sa was saved under a specific one\n",
    "#     # mag_data = loaded_data.get('mag_rtn_4sa') # Or whatever key it was saved under\n",
    "#     # if mag_data:\n",
    "#     #     # Inspect mag_data attributes as above\n",
    "#     #     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c98f6",
   "metadata": {},
   "source": [
    "Data Type Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f37c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotbot\n",
    "# from plotbot.data_classes.psp_data_types import data_types as psp_data_types_config\n",
    "\n",
    "# # Ensure debug prints are on to see the output from import_data_function\n",
    "# pm.show_debug = True\n",
    "# pm.show_variable_testing = True # If import_data_function uses this\n",
    "\n",
    "# # Define a short, common time range likely to have data for many types\n",
    "# # (Adjust if needed, ensure corresponding CDFs exist locally for types you want to test)\n",
    "# test_trange = ['2021-04-28 00:00:00', '2021-04-28 01:00:00'] \n",
    "\n",
    "# # List of data types to test (can be all keys from psp_data_types_config or a subset)\n",
    "# # For now, let's focus on 'mag_RTN' as it was problematic, and maybe a couple of others.\n",
    "# types_to_test = {\n",
    "#     'mag_RTN': plotbot.mag_rtn,\n",
    "#     'mag_RTN_4sa': plotbot.mag_rtn_4sa,\n",
    "#     # Add other types and their corresponding global plotbot instances if you want to test more\n",
    "#     # 'mag_SC': plotbot.mag_sc,\n",
    "#     # 'spe_sf0_pad': plotbot.epad, # Assuming epad is the global instance for spe_sf0_pad\n",
    "#     # 'spi_sf00_l3_mom': plotbot.proton # Assuming proton is the global instance\n",
    "# }\n",
    "\n",
    "# print(f\"--- Starting Data Load Test for Multiple Types ---\")\n",
    "# for type_key, global_instance in types_to_test.items():\n",
    "#     print(f\"--- Testing data_type: {type_key} ---\")\n",
    "#     try:\n",
    "#         # We are primarily interested in what import_data_function returns.\n",
    "#         # The call to plotbot.get_data will trigger it.\n",
    "#         # The KeyError would happen inside calculate_variables if the key is missing.\n",
    "#         plotbot.get_data(test_trange, global_instance)\n",
    "#         print(f\"  \u2705 plotbot.get_data call completed for {type_key}\")\n",
    "        \n",
    "#         # Optional: Check the state of the global instance if needed,\n",
    "#         # but the main goal is to see the *** IMPORT_DATA_DEBUG *** prints\n",
    "#         # print(f\"    {type_key}.datetime_array len: {len(global_instance.datetime_array) if global_instance.datetime_array is not None else 'None'}\")\n",
    "\n",
    "#     except KeyError as ke:\n",
    "#         print(f\"  \ud83d\udd34 KeyError for {type_key}: {ke}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  \ud83d\udd34 Other Error for {type_key}: {e}\")\n",
    "#     print(f\"--- Finished testing data_type: {type_key} ---\\n\")\n",
    "\n",
    "# print(f\"--- Data Load Test Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e36e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
