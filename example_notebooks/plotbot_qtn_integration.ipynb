{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# QTN Data Integration with PySpedas\n",
    "\n",
    "This notebook demonstrates how to download and work with PSP QTN (Quasi-Thermal Noise) data using pyspedas.\n",
    "QTN provides the most reliable density measurement from electric field instruments.\n",
    "We'll use the same date range as the WIND MFI test: 2022/06/01 20:00:00.000 to 2022/06/02 02:00:00.000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Download QTN data and determine file paths\n",
    "import pyspedas\n",
    "import os\n",
    "import cdflib\n",
    "\n",
    "# Define the same date range as WIND MFI test\n",
    "trange = ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
    "qtn_datatype = 'sqtn_rfs_V1V2'  # QTN data for most reliable density measurement\n",
    "\n",
    "print(f\"Downloading PSP QTN data for time range: {trange}\")\n",
    "print(f\"Datatype: {qtn_datatype}\")\n",
    "\n",
    "# Download with downloadonly=True and notplot=True\n",
    "downloaded_files = pyspedas.psp.fields(\n",
    "    trange=trange, \n",
    "    datatype=qtn_datatype, \n",
    "    level='l3', \n",
    "    time_clip=True,\n",
    "    get_support_data=True,\n",
    "    downloadonly=True,  # Only download, don't load into memory\n",
    "    notplot=True        # Don't create plots\n",
    ")\n",
    "\n",
    "print(f\"\\nDownload completed. Files returned: {len(downloaded_files) if downloaded_files else 0}\")\n",
    "\n",
    "if downloaded_files:\n",
    "    for i, file_path in enumerate(downloaded_files):\n",
    "        print(f\"File {i+1}: {file_path}\")\n",
    "        \n",
    "        # Get absolute path\n",
    "        abs_path = os.path.abspath(file_path)\n",
    "        print(f\"  Absolute path: {abs_path}\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if os.path.exists(abs_path):\n",
    "            file_size = os.path.getsize(abs_path) / (1024*1024)  # MB\n",
    "            print(f\"  File size: {file_size:.2f} MB\")\n",
    "            print(f\"  File exists: Yes\")\n",
    "        else:\n",
    "            print(f\"  File exists: No\")\n",
    "        \n",
    "        # Show directory structure\n",
    "        directory = os.path.dirname(abs_path)\n",
    "        print(f\"  Directory: {directory}\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"No files were downloaded or found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Extract variable names from the CDF file\n",
    "import cdflib\n",
    "\n",
    "if downloaded_files and len(downloaded_files) > 0:\n",
    "    # Use the first downloaded file\n",
    "    cdf_file_path = downloaded_files[0]\n",
    "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
    "    \n",
    "    print(f\"Analyzing CDF file: {os.path.basename(abs_cdf_path)}\")\n",
    "    print(f\"Full path: {abs_cdf_path}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Open the CDF file\n",
    "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
    "            # Get CDF info\n",
    "            cdf_info = cdf.cdf_info()\n",
    "            \n",
    "            print(f\"CDF File Info:\")\n",
    "            print(f\"  CDF Version: {cdf_info.Version}\")\n",
    "            print(f\"  Encoding: {getattr(cdf_info, 'Encoding', 'Unknown')}\")\n",
    "            print(f\"  Majority: {getattr(cdf_info, 'Majority', 'Unknown')}\")\n",
    "            print(f\"  Number of rDimensions: {getattr(cdf_info, 'Num_rdim', 0)}\")\n",
    "            print(f\"  rDimension sizes: {getattr(cdf_info, 'rDim_sizes', [])}\")\n",
    "            print(f\"  Number of zVariables: {len(cdf_info.zVariables)}\")\n",
    "            print(f\"  Number of rVariables: {len(cdf_info.rVariables)}\")\n",
    "            print(f\"  Compressed: {getattr(cdf_info, 'Compressed', 'Unknown')}\")\n",
    "            print(f\"  Checksum: {getattr(cdf_info, 'Checksum', 'Unknown')}\")\n",
    "            print()\n",
    "            \n",
    "            # List all zVariables (most data variables)\n",
    "            print(\"zVariables (data variables):\")\n",
    "            for i, var_name in enumerate(cdf_info.zVariables):\n",
    "                try:\n",
    "                    var_info = cdf.varinq(var_name)\n",
    "                    print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # List all rVariables (usually metadata)\n",
    "            if cdf_info.rVariables:\n",
    "                print(\"rVariables (metadata variables):\")\n",
    "                for i, var_name in enumerate(cdf_info.rVariables):\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
    "            else:\n",
    "                print(\"No rVariables found.\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Look specifically for QTN/density-related variables\n",
    "            print(\"QTN/Density-related variables (containing 'qtn', 'dens', 'n_elec', or 'density'):\")\n",
    "            qtn_vars = []\n",
    "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
    "            \n",
    "            for var_name in all_vars:\n",
    "                lower_name = var_name.lower()\n",
    "                if any(keyword in lower_name for keyword in ['qtn', 'dens', 'n_elec', 'density', 'electron_density', 'ne']):\n",
    "                    qtn_vars.append(var_name)\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  \u2022 {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  \u2022 {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            if not qtn_vars:\n",
    "                print(\"  No obvious QTN/density-related variables found.\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Look for time variables\n",
    "            print(\"Time variables (containing 'epoch' or 'time'):\")\n",
    "            time_vars = []\n",
    "            for var_name in all_vars:\n",
    "                lower_name = var_name.lower()\n",
    "                if 'epoch' in lower_name or 'time' in lower_name:\n",
    "                    time_vars.append(var_name)\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  \u2022 {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  \u2022 {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            if not time_vars:\n",
    "                print(\"  No time variables found.\")\n",
    "            \n",
    "            print()\n",
    "            print(f\"Total variables found: {len(all_vars)}\")\n",
    "            print(f\"QTN/density-related variables: {len(qtn_vars)}\")\n",
    "            print(f\"Time variables: {len(time_vars)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CDF file: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "else:\n",
    "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Examine electron density and QTN variables specifically\n",
    "import numpy as np\n",
    "\n",
    "if downloaded_files and len(downloaded_files) > 0:\n",
    "    cdf_file_path = downloaded_files[0]\n",
    "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
    "    \n",
    "    print(f\"Examining electron density and QTN variables in: {os.path.basename(abs_cdf_path)}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
    "            # Get all variable names to search for relevant ones\n",
    "            cdf_info = cdf.cdf_info()\n",
    "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
    "            \n",
    "            # Look for common QTN variable names\n",
    "            potential_vars = ['n_elec', 'electron_density', 'density', 'DENS', 'ne', 'N_ELEC']\n",
    "            \n",
    "            found_vars = []\n",
    "            for var in potential_vars:\n",
    "                if var in all_vars:\n",
    "                    found_vars.append(var)\n",
    "            \n",
    "            # If no exact matches, look for variables containing density-related keywords\n",
    "            if not found_vars:\n",
    "                print(\"No exact matches found, searching for variables containing density keywords...\")\n",
    "                for var_name in all_vars:\n",
    "                    lower_name = var_name.lower()\n",
    "                    if any(keyword in lower_name for keyword in ['dens', 'elec', 'ne', 'qtn']):\n",
    "                        found_vars.append(var_name)\n",
    "            \n",
    "            if found_vars:\n",
    "                for var_name in found_vars[:3]:  # Limit to first 3 variables to avoid too much output\n",
    "                    print(f\"{var_name} (Potential Electron Density/QTN Variable):\")\n",
    "                    try:\n",
    "                        var_data = cdf.varget(var_name)\n",
    "                        print(f\"  Data type: {type(var_data)}\")\n",
    "                        print(f\"  Array shape: {var_data.shape}\")\n",
    "                        print(f\"  Data length: {len(var_data) if hasattr(var_data, '__len__') else 'N/A'}\")\n",
    "                        \n",
    "                        if hasattr(var_data, 'dtype') and np.issubdtype(var_data.dtype, np.number):\n",
    "                            print(f\"  Min value: {np.nanmin(var_data):.6f}\")\n",
    "                            print(f\"  Max value: {np.nanmax(var_data):.6f}\")\n",
    "                            print(f\"  Mean value: {np.nanmean(var_data):.6f}\")\n",
    "                            print(f\"  Number of valid (non-NaN) values: {np.sum(~np.isnan(var_data))}\")\n",
    "                            print(f\"  Number of NaN values: {np.sum(np.isnan(var_data))}\")\n",
    "                            \n",
    "                            # Show first few values if 1D array\n",
    "                            if len(var_data.shape) == 1:\n",
    "                                print(f\"  First 10 values: {var_data[:10]}\")\n",
    "                            else:\n",
    "                                print(f\"  First value shape: {var_data[0].shape if len(var_data) > 0 else 'Empty'}\")\n",
    "                        else:\n",
    "                            print(f\"  Data type: {var_data.dtype if hasattr(var_data, 'dtype') else 'Unknown'}\")\n",
    "                            if hasattr(var_data, '__len__') and len(var_data) > 0:\n",
    "                                print(f\"  First few values: {var_data[:5]}\")\n",
    "                        \n",
    "                        # Get variable attributes\n",
    "                        try:\n",
    "                            var_attrs = cdf.varattsget(var_name)\n",
    "                            if \"UNITS\" in var_attrs:\n",
    "                                print(f\"  Units: {var_attrs['UNITS']}\")\n",
    "                            if \"FIELDNAM\" in var_attrs:\n",
    "                                print(f\"  Field name: {var_attrs['FIELDNAM']}\")\n",
    "                            if \"CATDESC\" in var_attrs:\n",
    "                                print(f\"  Description: {var_attrs['CATDESC']}\")\n",
    "                        except:\n",
    "                            pass\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"  Error reading {var_name}: {e}\")\n",
    "                    \n",
    "                    print()\n",
    "            \n",
    "            else:\n",
    "                print(\"No density or QTN-related variables found.\")\n",
    "                print(\"Available variables:\")\n",
    "                for var in all_vars[:10]:  # Show first 10 variables\n",
    "                    print(f\"  - {var}\")\n",
    "                if len(all_vars) > 10:\n",
    "                    print(f\"  ... and {len(all_vars) - 10} more variables\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Also check the time variable for context\n",
    "            print(\"Epoch (Time variable for reference):\")\n",
    "            try:\n",
    "                epoch_data = cdf.varget(\"Epoch\")\n",
    "                print(f\"  Data type: {type(epoch_data)}\")\n",
    "                print(f\"  Array shape: {epoch_data.shape}\")\n",
    "                print(f\"  Data length: {len(epoch_data)}\")\n",
    "                print(f\"  First timestamp: {cdflib.cdfepoch.to_datetime(epoch_data[0])}\")\n",
    "                print(f\"  Last timestamp: {cdflib.cdfepoch.to_datetime(epoch_data[-1])}\")\n",
    "                print(f\"  Total time span: {cdflib.cdfepoch.to_datetime(epoch_data[-1]) - cdflib.cdfepoch.to_datetime(epoch_data[0])}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error reading Epoch: {e}\")\n",
    "                # Try alternative time variable names\n",
    "                time_vars = [v for v in all_vars if 'time' in v.lower() or 'epoch' in v.lower()]\n",
    "                if time_vars:\n",
    "                    print(f\"  Found alternative time variables: {time_vars}\")\n",
    "            \n",
    "            print()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error opening CDF file: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "else:\n",
    "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Alpha Particle Data Integration with PySpedas\n",
    "\n",
    "This notebook demonstrates how to download and work with PSP alpha particle data using pyspedas.\n",
    "We'll use the same date range as the WIND MFI test: 2022/06/01 20:00:00.000 to 2022/06/02 02:00:00.000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Download alpha data and determine file paths\n",
    "import pyspedas\n",
    "import os\n",
    "import cdflib\n",
    "\n",
    "# Define the same date range as WIND MFI test\n",
    "trange = ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
    "spi_sf0a_datatype = 'spi_sf0a_l3_mom'  # Alpha particle moments\n",
    "\n",
    "print(f\"Downloading PSP alpha data for time range: {trange}\")\n",
    "print(f\"Datatype: {spi_sf0a_datatype}\")\n",
    "\n",
    "# Download with downloadonly=True and notplot=True\n",
    "downloaded_files = pyspedas.psp.spi(\n",
    "    trange=trange, \n",
    "    datatype=spi_sf0a_datatype, \n",
    "    level='l3', \n",
    "    time_clip=True,\n",
    "    downloadonly=True,  # Only download, don't load into memory\n",
    "    notplot=True        # Don't create plots\n",
    ")\n",
    "\n",
    "print(f\"\\nDownload completed. Files returned: {len(downloaded_files) if downloaded_files else 0}\")\n",
    "\n",
    "if downloaded_files:\n",
    "    for i, file_path in enumerate(downloaded_files):\n",
    "        print(f\"File {i+1}: {file_path}\")\n",
    "        \n",
    "        # Get absolute path\n",
    "        abs_path = os.path.abspath(file_path)\n",
    "        print(f\"  Absolute path: {abs_path}\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if os.path.exists(abs_path):\n",
    "            file_size = os.path.getsize(abs_path) / (1024*1024)  # MB\n",
    "            print(f\"  File size: {file_size:.2f} MB\")\n",
    "            print(f\"  File exists: Yes\")\n",
    "        else:\n",
    "            print(f\"  File exists: No\")\n",
    "        \n",
    "        # Show directory structure\n",
    "        directory = os.path.dirname(abs_path)\n",
    "        print(f\"  Directory: {directory}\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"No files were downloaded or found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Extract variable names from the CDF file\n",
    "import cdflib\n",
    "\n",
    "if downloaded_files and len(downloaded_files) > 0:\n",
    "    # Use the first downloaded file\n",
    "    cdf_file_path = downloaded_files[0]\n",
    "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
    "    \n",
    "    print(f\"Analyzing CDF file: {os.path.basename(abs_cdf_path)}\")\n",
    "    print(f\"Full path: {abs_cdf_path}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Open the CDF file\n",
    "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
    "            # Get CDF info\n",
    "            cdf_info = cdf.cdf_info()\n",
    "            \n",
    "            print(f\"CDF File Info:\")\n",
    "            print(f\"  CDF Version: {cdf_info.Version}\")\n",
    "            print(f\"  Encoding: {getattr(cdf_info, 'Encoding', 'Unknown')}\")\n",
    "            print(f\"  Majority: {getattr(cdf_info, 'Majority', 'Unknown')}\")\n",
    "            print(f\"  Number of rDimensions: {getattr(cdf_info, 'Num_rdim', 0)}\")\n",
    "            print(f\"  rDimension sizes: {getattr(cdf_info, 'rDim_sizes', [])}\")\n",
    "            print(f\"  Number of zVariables: {len(cdf_info.zVariables)}\")\n",
    "            print(f\"  Number of rVariables: {len(cdf_info.rVariables)}\")\n",
    "            print(f\"  Compressed: {getattr(cdf_info, 'Compressed', 'Unknown')}\")\n",
    "            print(f\"  Checksum: {getattr(cdf_info, 'Checksum', 'Unknown')}\")\n",
    "            print()\n",
    "            \n",
    "            # List all zVariables (most data variables)\n",
    "            print(\"zVariables (data variables):\")\n",
    "            for i, var_name in enumerate(cdf_info.zVariables):\n",
    "                try:\n",
    "                    var_info = cdf.varinq(var_name)\n",
    "                    print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # List all rVariables (usually metadata)\n",
    "            if cdf_info.rVariables:\n",
    "                print(\"rVariables (metadata variables):\")\n",
    "                for i, var_name in enumerate(cdf_info.rVariables):\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
    "            else:\n",
    "                print(\"No rVariables found.\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Look specifically for alpha-related variables\n",
    "            print(\"Alpha-related variables (containing 'alpha', 'na', or 'va'):\")\n",
    "            alpha_vars = []\n",
    "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
    "            \n",
    "            for var_name in all_vars:\n",
    "                lower_name = var_name.lower()\n",
    "                if any(keyword in lower_name for keyword in ['alpha', 'na', 'va', 'temp_alpha', 'vel_alpha']):\n",
    "                    alpha_vars.append(var_name)\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  \u2022 {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  \u2022 {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            if not alpha_vars:\n",
    "                print(\"  No obvious alpha-related variables found.\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Look for time variables\n",
    "            print(\"Time variables (containing 'epoch' or 'time'):\")\n",
    "            time_vars = []\n",
    "            for var_name in all_vars:\n",
    "                lower_name = var_name.lower()\n",
    "                if 'epoch' in lower_name or 'time' in lower_name:\n",
    "                    time_vars.append(var_name)\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  \u2022 {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  \u2022 {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            if not time_vars:\n",
    "                print(\"  No time variables found.\")\n",
    "            \n",
    "            print()\n",
    "            print(f\"Total variables found: {len(all_vars)}\")\n",
    "            print(f\"Alpha-related variables: {len(alpha_vars)}\")\n",
    "            print(f\"Time variables: {len(time_vars)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CDF file: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "else:\n",
    "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Particle Data Integration with PySpedas\n",
    "\n",
    "This notebook demonstrates how to download and work with PSP alpha particle data using pyspedas.\n",
    "We'll use the same date range as the WIND MFI test: 2022/06/01 20:00:00.000 to 2022/06/02 02:00:00.000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Download alpha data and determine file paths\n",
    "import pyspedas\n",
    "import os\n",
    "import cdflib\n",
    "\n",
    "# Define the same date range as WIND MFI test\n",
    "trange = ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
    "spi_sf0a_datatype = 'spi_sf0a_l3_mom'  # Alpha particle moments\n",
    "\n",
    "print(f\"Downloading PSP alpha data for time range: {trange}\")\n",
    "print(f\"Datatype: {spi_sf0a_datatype}\")\n",
    "\n",
    "# Download with downloadonly=True and notplot=True\n",
    "downloaded_files = pyspedas.psp.spi(\n",
    "    trange=trange, \n",
    "    datatype=spi_sf0a_datatype, \n",
    "    level='l3', \n",
    "    time_clip=True,\n",
    "    downloadonly=True,  # Only download, don't load into memory\n",
    "    notplot=True        # Don't create plots\n",
    ")\n",
    "\n",
    "print(f\"\\nDownload completed. Files returned: {len(downloaded_files) if downloaded_files else 0}\")\n",
    "\n",
    "if downloaded_files:\n",
    "    for i, file_path in enumerate(downloaded_files):\n",
    "        print(f\"File {i+1}: {file_path}\")\n",
    "        \n",
    "        # Get absolute path\n",
    "        abs_path = os.path.abspath(file_path)\n",
    "        print(f\"  Absolute path: {abs_path}\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if os.path.exists(abs_path):\n",
    "            file_size = os.path.getsize(abs_path) / (1024*1024)  # MB\n",
    "            print(f\"  File size: {file_size:.2f} MB\")\n",
    "            print(f\"  File exists: Yes\")\n",
    "        else:\n",
    "            print(f\"  File exists: No\")\n",
    "        \n",
    "        # Show directory structure\n",
    "        directory = os.path.dirname(abs_path)\n",
    "        print(f\"  Directory: {directory}\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"No files were downloaded or found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Extract variable names from the CDF file\n",
    "import cdflib\n",
    "\n",
    "if downloaded_files and len(downloaded_files) > 0:\n",
    "    # Use the first downloaded file\n",
    "    cdf_file_path = downloaded_files[0]\n",
    "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
    "    \n",
    "    print(f\"Analyzing CDF file: {os.path.basename(abs_cdf_path)}\")\n",
    "    print(f\"Full path: {abs_cdf_path}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Open the CDF file\n",
    "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
    "            # Get CDF info\n",
    "            cdf_info = cdf.cdf_info()\n",
    "            \n",
    "            print(f\"CDF File Info:\")\n",
    "            print(f\"  CDF Version: {cdf_info.version}\")\n",
    "            print(f\"  Number of dimensions: {cdf_info.num_dims}\")\n",
    "            print(f\"  Number of zVariables: {len(cdf_info.zVariables)}\")\n",
    "            print(f\"  Number of rVariables: {len(cdf_info.rVariables)}\")\n",
    "            print()\n",
    "            \n",
    "            # List all zVariables (most data variables)\n",
    "            print(\"zVariables (data variables):\")\n",
    "            for i, var_name in enumerate(cdf_info.zVariables):\n",
    "                try:\n",
    "                    var_info = cdf.varinq(var_name)\n",
    "                    print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # List all rVariables (usually metadata)\n",
    "            if cdf_info.rVariables:\n",
    "                print(\"rVariables (metadata variables):\")\n",
    "                for i, var_name in enumerate(cdf_info.rVariables):\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
    "            else:\n",
    "                print(\"No rVariables found.\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Look specifically for alpha-related variables\n",
    "            print(\"Alpha-related variables (containing 'alpha', 'na', or 'va'):\")\n",
    "            alpha_vars = []\n",
    "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
    "            \n",
    "            for var_name in all_vars:\n",
    "                lower_name = var_name.lower()\n",
    "                if any(keyword in lower_name for keyword in ['alpha', 'na', 'va', 'temp_alpha', 'vel_alpha']):\n",
    "                    alpha_vars.append(var_name)\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  \u2022 {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  \u2022 {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            if not alpha_vars:\n",
    "                print(\"  No obvious alpha-related variables found.\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Look for time variables\n",
    "            print(\"Time variables (containing 'epoch' or 'time'):\")\n",
    "            time_vars = []\n",
    "            for var_name in all_vars:\n",
    "                lower_name = var_name.lower()\n",
    "                if 'epoch' in lower_name or 'time' in lower_name:\n",
    "                    time_vars.append(var_name)\n",
    "                    try:\n",
    "                        var_info = cdf.varinq(var_name)\n",
    "                        print(f\"  \u2022 {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  \u2022 {var_name:30s} - Error getting info: {e}\")\n",
    "            \n",
    "            if not time_vars:\n",
    "                print(\"  No time variables found.\")\n",
    "            \n",
    "            print()\n",
    "            print(f\"Total variables found: {len(all_vars)}\")\n",
    "            print(f\"Alpha-related variables: {len(alpha_vars)}\")\n",
    "            print(f\"Time variables: {len(time_vars)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CDF file: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "else:\n",
    "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
